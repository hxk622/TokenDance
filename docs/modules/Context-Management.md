# Contextç®¡ç†æœºåˆ¶è®¾è®¡æ–‡æ¡£

> **æ ¸å¿ƒæ›´æ–° (2026-01-10)**: é›†æˆå¤šç§Ÿæˆ·ã€æ–‡ä»¶ç³»ç»ŸæŒ‡é’ˆã€å‹ç¼©ç­–ç•¥
> - **å¤šç§Ÿæˆ·æ¶æ„**ï¼šOrganization â†’ Team â†’ Workspace ä¸‰å±‚éš”ç¦»
> - **Dual Context Streams**ï¼šWorking Memoryï¼ˆKV-Cacheï¼‰+ File Systemï¼ˆæŒä¹…åŒ–ï¼‰
> - **æ™ºèƒ½å‹ç¼©**ï¼šæ–‡ä»¶ç³»ç»ŸæŒ‡é’ˆ + è‡ªåŠ¨æ¢å…¥æ¢å‡º
> - å‚è€ƒï¼š[FileSystem.md](./FileSystem.md), [Context-Compression.md](./Context-Compression.md), [Multi-Tenancy.md](../architecture/Multi-Tenancy.md)

## 1. æ ¸å¿ƒé—®é¢˜

**é•¿å¯¹è¯åœºæ™¯ä¸‹çš„Contextçˆ†ç‚¸**ï¼š
- 100è½®å¯¹è¯ Ã— 1000 tokens/è½® = 100K tokens
- æˆæœ¬ï¼š$300/æ¬¡è¯·æ±‚
- å»¶è¿Ÿï¼š10-15ç§’
- è¶…è¿‡æ¨¡å‹çª—å£é™åˆ¶

**å·¥ç¨‹çŸ›ç›¾**ï¼š
- Agentéœ€è¦å†å²ä¿¡æ¯åšå†³ç­–
- Contextè¶Šé•¿ï¼Œæˆæœ¬è¶Šé«˜ï¼Œæ€§èƒ½è¶Šå·®
- ç®€å•æˆªæ–­ä¼šä¸¢å¤±å…³é”®ä¿¡æ¯

## 2. è®¾è®¡åŸåˆ™

### 2.1 åˆ†å±‚å­˜å‚¨åŸåˆ™ï¼ˆDual Context Streams + å‹ç¼©ï¼‰

åŸºäº Manus çš„ "todo.md æ˜¯çµé­‚" ç†å¿µï¼ŒTokenDance é‡‡ç”¨ **åŒé‡åˆ†èº« + æ™ºèƒ½å‹ç¼©** æ¶æ„ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  äº”å±‚è®°å¿†æ¶æ„ï¼ˆå¤šç§Ÿæˆ· + å‹ç¼©ï¼‰                               â”‚
â”‚                                                                  â”‚
â”‚  Layer 0: FileSystem (é•¿æœŸè®°å¿†) ğŸ†•                             â”‚
â”‚  - æ— é™å®¹é‡ï¼ˆæ•° TBï¼‰ï¼ŒæŒä¹…åŒ–å­˜å‚¨                              â”‚
â”‚  - æŒ‰ Org/Team/Workspace ç‰©ç†éš”ç¦»                             â”‚
â”‚  - åŸå§‹æ•°æ®å®Œæ•´ä¿ç•™ï¼Œå¯æ¢å¤                                   â”‚
â”‚                         â†“ å‹ç¼©æŒ‡é’ˆ                              â”‚
â”‚  Layer 1: Global Static Prefix (å…¨å±€é™æ€å‰ç¼€)                 â”‚
â”‚  - å·¥å…·å®šä¹‰ã€FSM çŠ¶æ€ã€æ ¸å¿ƒè§„åˆ™                              â”‚
â”‚  - æ¯ä¸ª Org ç‹¬ç«‹ï¼Œå†…éƒ¨ Agent å…±äº«ï¼ˆCopy-on-Writeï¼‰         â”‚
â”‚                         â†“ æŒ‚è½½                                 â”‚
â”‚  Layer 2: Skill Cache (é¢†åŸŸä¸“å®¶çŸ¥è¯†)                        â”‚
â”‚  - Skill L2 æŒ‡ä»¤                                              â”‚
â”‚  - Team çº§åˆ«å…±äº«ï¼Œæ‡’åŠ è½½ + å¤ç”¨                              â”‚
â”‚                         â†“ è¿½åŠ                                 â”‚
â”‚  Layer 3: Session Cache (ä¼šè¯ä¸Šä¸‹æ–‡)                        â”‚
â”‚  - ç”¨æˆ·æŒ‡ä»¤ã€Agent æ¨ç†ã€å·¥å…·è¿”å›                           â”‚
â”‚  - çƒ­æ•°æ®ä¿ç•™åœ¨ KV-Cacheï¼Œå†·æ•°æ®æ¢å‡ºåˆ° FileSystem        â”‚
â”‚  - å‹ç¼©æŒ‡é’ˆï¼šæ‘˜è¦ + è·¯å¾„ + æ£€ç´¢æç¤º                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å‚è€ƒè¯¦ç»†è®¾è®¡ï¼š
- [KV-Cache-Advanced.md](./KV-Cache-Advanced.md) - å±‚æ¬¡åŒ–ç¼“å­˜æ¶æ„
- [Context-Compression.md](./Context-Compression.md) - å‹ç¼©ç­–ç•¥å’Œæ–‡ä»¶ç³»ç»ŸæŒ‡é’ˆ
```

### 2.2 æŒ‰éœ€åŠ è½½åŸåˆ™
```python
# ä¸é¢„åŠ è½½æ‰€æœ‰æ•°æ®ï¼ŒAgentæŒ‰éœ€è¯»å–

# âŒ é”™è¯¯åšæ³•
context = load_all_messages()  # åŠ è½½100K tokens

# âœ… æ­£ç¡®åšæ³•
context = {
    "summary": load_summary(),        # 500 tokens
    "recent_messages": load_recent(10),  # 10K tokens
    "file_index": list_workspace_files()  # Agentéœ€è¦æ—¶å†è¯»å–
}
```

### 2.3 å¢é‡æ›´æ–°åŸåˆ™
```python
# é¿å…æ¯æ¬¡é‡æ–°æ‘˜è¦å…¨éƒ¨å†å²

# âŒ ä½æ•ˆåšæ³•
def update_summary():
    all_messages = load_all()  # é‡æ–°å¤„ç†100è½®
    return summarize(all_messages)

# âœ… é«˜æ•ˆåšæ³•
def update_summary_incremental():
    old_summary = load_latest_summary()
    new_messages = load_unsummarized()
    return merge_summary(old_summary, new_messages)  # åªå¤„ç†å¢é‡
```

## 3. æ¶æ„è®¾è®¡

### 3.1 æ•°æ®æ¨¡å‹

```sql
-- æ¶ˆæ¯è¡¨ï¼ˆæ”¯æŒæ‘˜è¦æ ‡è®°ï¼‰
CREATE TABLE messages (
    id UUID PRIMARY KEY,
    session_id UUID NOT NULL,
    role TEXT NOT NULL,  -- user/assistant/system/tool
    content TEXT,
    
    -- å·¥å…·è°ƒç”¨å…ƒæ•°æ®
    tool_name TEXT,
    tool_args JSONB,
    tool_result JSONB,
    
    -- æ‘˜è¦æ ‡è®°
    is_summarized BOOLEAN DEFAULT FALSE,
    summary_id UUID REFERENCES conversation_summaries(id),
    
    -- Tokenè®¡æ•°
    token_count INT,
    
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    INDEX idx_messages_session (session_id, created_at),
    INDEX idx_messages_unsummarized (session_id, is_summarized)
);

-- å¯¹è¯æ‘˜è¦è¡¨
CREATE TABLE conversation_summaries (
    id UUID PRIMARY KEY,
    session_id UUID NOT NULL,
    
    -- æ‘˜è¦è¦†ç›–çš„æ¶ˆæ¯èŒƒå›´
    start_message_id UUID NOT NULL,
    end_message_id UUID NOT NULL,
    message_count INT,
    
    -- æ‘˜è¦å†…å®¹ï¼ˆç»“æ„åŒ– + æ–‡æœ¬ï¼‰
    summary JSONB NOT NULL,  -- ç»“æ„åŒ–æ•°æ®
    summary_text TEXT NOT NULL,  -- ç»™Agentçœ‹çš„ç‰ˆæœ¬
    
    -- å‹ç¼©æ•ˆæœ
    original_token_count INT,
    summary_token_count INT,
    compression_ratio FLOAT,
    
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    INDEX idx_summaries_session (session_id, created_at DESC)
);

-- æ‘˜è¦ç»“æ„ï¼ˆJSONBæ ¼å¼ï¼‰
{
  "user_goal": "æ­å»ºTokenDanceå¹³å°",
  "completed_tasks": [
    "åˆ›å»ºäº†7ä¸ªè®¾è®¡æ–‡æ¡£",
    "å®ç°äº†Skillä¸‰çº§åŠ è½½æœºåˆ¶"
  ],
  "key_decisions": [
    {
      "decision": "ä½¿ç”¨Plan Recitationé˜²æ­¢Lost-in-the-Middle",
      "reason": "TODOåˆ—è¡¨æ”¾æœ«å°¾ï¼Œé¿å…è¢«é—å¿˜",
      "timestamp": "2026-01-08T10:00:00Z"
    }
  ],
  "current_status": "æ­£åœ¨è®¾è®¡Memoryæ¨¡å—",
  "pending_todos": ["åˆ›å»ºMemory-Design.md"],
  "important_context": {
    "tech_stack": "Vue3 + FastAPI + PostgreSQL",
    "workspace_path": "/Users/x/TokenDance",
    "key_files": ["docs/architecture/HLD.md"]
  }
}
```

### 3.2 æ ¸å¿ƒç»„ä»¶

```python
# packages/core/context/manager.py

from typing import List, Optional
from pydantic import BaseModel

class ConversationSummary(BaseModel):
    """å¯¹è¯æ‘˜è¦ç»“æ„"""
    user_goal: str
    completed_tasks: List[str]
    key_decisions: List[dict]
    current_status: str
    pending_todos: List[str]
    important_context: dict

class ConversationManager:
    """å¯¹è¯Contextç®¡ç†å™¨ï¼ˆå¤šç§Ÿæˆ· + å‹ç¼©ï¼‰"""
    
    # é…ç½®å‚æ•°
    SUMMARY_THRESHOLD = 50000      # è¶…è¿‡æ­¤tokensè§¦å‘æ‘˜è¦
    KEEP_RECENT_TURNS = 10         # ä¿ç•™æœ€è¿‘Nè½®å®Œæ•´æ¶ˆæ¯
    INCREMENTAL_BATCH_SIZE = 5     # å¢é‡æ›´æ–°æ‰¹æ¬¡å¤§å°
    COMPRESSION_THRESHOLD = 10240  # > 10KB è‡ªåŠ¨å‹ç¼©åˆ°æ–‡ä»¶ç³»ç»Ÿ ğŸ†•
    
    def __init__(
        self,
        session_id: str,
        workspace_id: str,      # ğŸ†• Workspace ID
        org_id: str,            # ğŸ†• Organization ID
        team_id: str,           # ğŸ†• Team ID
        db,
        llm,
        file_manager,
        compressor,             # ğŸ†• ContextCompressor å®ä¾‹
        decompressor            # ğŸ†• ContextDecompressor å®ä¾‹
    ):
        self.session_id = session_id
        self.workspace_id = workspace_id
        self.org_id = org_id
        self.team_id = team_id
        self.db = db
        self.llm = llm
        self.file_manager = file_manager  # FileManager å®ä¾‹
        self.compressor = compressor
        self.decompressor = decompressor
    
    async def get_context_for_agent(self) -> dict:
        """
        è·å–Agentçš„ä¸Šä¸‹æ–‡ï¼ˆæ ¸å¿ƒæ¥å£ï¼‰
        
        å®ç° Dual Context Streamsï¼š
        1. Working Memory: æ•°æ®åº“æ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯ï¼ˆç²¾ç®€ï¼‰
        2. File System: workspace/ æ–‡ä»¶ï¼ˆå®Œæ•´ï¼‰
        
        è¿”å›ç»“æ„ï¼š
        {
            "working_memory": {        # Stream 1: æ•°æ®åº“
                "summary": Optional[str],
                "messages": List[Message]
            },
            "file_system": {           # Stream 2: æ–‡ä»¶ç³»ç»Ÿï¼ˆå‚è€ƒ FileSystem.mdï¼‰
                "memory": str,         # workspace/context/memory.md
                "learnings": str,      # workspace/context/learnings.md
                "rules": str,          # workspace/context/rules.md
                "active_tasks": List   # workspace/tasks/*.md (in_progress)
            }
        }
        """
        # 1. è·å–æ‰€æœ‰æ¶ˆæ¯
        messages = await self.db.get_messages(self.session_id)
        total_tokens = sum(m.token_count for m in messages)
        
        # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ‘˜è¦
        if total_tokens < self.SUMMARY_THRESHOLD:
            return {
                "summary": None,
                "messages": messages,
                "workspace": await self.fs.get_file_index(self.session_id)
            }
        
        # 3. å¤„ç†æ‘˜è¦
        await self._ensure_summary_updated(messages)
        
        # 4. æ„å»ºContext
        return await self._build_context_with_summary()
    
    async def _ensure_summary_updated(self, messages: List):
        """ç¡®ä¿æ‘˜è¦æ˜¯æœ€æ–°çš„"""
        summary = await self.db.get_latest_summary(self.session_id)
        
        if not summary:
            # é¦–æ¬¡æ‘˜è¦
            await self._create_initial_summary(messages)
        else:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°
            unsummarized_count = len([m for m in messages if not m.is_summarized])
            
            if unsummarized_count >= self.INCREMENTAL_BATCH_SIZE:
                await self._update_summary_incremental(messages)
    
    async def _create_initial_summary(self, messages: List):
        """é¦–æ¬¡åˆ›å»ºæ‘˜è¦"""
        # è®¡ç®—è¦æ‘˜è¦çš„èŒƒå›´ï¼ˆä¿ç•™æœ€è¿‘Nè½®ï¼‰
        cutoff_index = max(0, len(messages) - self.KEEP_RECENT_TURNS)
        to_summarize = messages[:cutoff_index]
        
        if not to_summarize:
            return
        
        # è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
        summary = await self._generate_summary(to_summarize)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        await self.db.create_summary(
            session_id=self.session_id,
            start_message_id=to_summarize[0].id,
            end_message_id=to_summarize[-1].id,
            message_count=len(to_summarize),
            summary=summary.model_dump(),
            summary_text=self._format_summary_text(summary),
            original_token_count=sum(m.token_count for m in to_summarize),
            summary_token_count=await self.llm.count_tokens(
                self._format_summary_text(summary)
            )
        )
        
        # æ ‡è®°æ¶ˆæ¯ä¸ºå·²æ‘˜è¦
        for msg in to_summarize:
            await self.db.mark_message_summarized(msg.id)
    
    async def _update_summary_incremental(self, messages: List):
        """å¢é‡æ›´æ–°æ‘˜è¦"""
        existing = await self.db.get_latest_summary(self.session_id)
        new_messages = [m for m in messages if not m.is_summarized]
        
        # è®¡ç®—è¦æ–°å¢æ‘˜è¦çš„èŒƒå›´
        cutoff = max(0, len(new_messages) - self.KEEP_RECENT_TURNS)
        to_add = new_messages[:cutoff]
        
        if not to_add:
            return
        
        # å¢é‡æ‘˜è¦ï¼šåŸºäºæ—§æ‘˜è¦ + æ–°æ¶ˆæ¯
        old_summary = ConversationSummary(**existing.summary)
        updated_summary = await self._merge_summary(old_summary, to_add)
        
        # ä¿å­˜æ–°æ‘˜è¦
        await self.db.create_summary(
            session_id=self.session_id,
            start_message_id=existing.start_message_id,  # èµ·ç‚¹ä¸å˜
            end_message_id=to_add[-1].id,
            message_count=existing.message_count + len(to_add),
            summary=updated_summary.model_dump(),
            summary_text=self._format_summary_text(updated_summary),
            original_token_count=existing.original_token_count + 
                                sum(m.token_count for m in to_add),
            summary_token_count=await self.llm.count_tokens(
                self._format_summary_text(updated_summary)
            )
        )
        
        # æ ‡è®°æ¶ˆæ¯
        for msg in to_add:
            await self.db.mark_message_summarized(msg.id)
    
    async def _generate_summary(self, messages: List) -> ConversationSummary:
        """ç”Ÿæˆæ‘˜è¦ï¼ˆè°ƒç”¨LLMï¼‰"""
        prompt = f"""
è¯·å°†ä»¥ä¸‹å¯¹è¯å‹ç¼©ä¸ºç»“æ„åŒ–æ‘˜è¦ã€‚ä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼Œä¸¢å¼ƒå†—ä½™ç»†èŠ‚ã€‚

å¯¹è¯å†…å®¹ï¼š
{self._format_messages_for_llm(messages)}

è¦æ±‚ï¼š
1. æå–ç”¨æˆ·çš„æ ¸å¿ƒç›®æ ‡ï¼ˆuser_goalï¼‰
2. åˆ—å‡ºå·²å®Œæˆçš„å…³é”®ä»»åŠ¡ï¼ˆcompleted_tasksï¼‰ï¼ŒæŒ‰æ—¶é—´é¡ºåº
3. è®°å½•é‡è¦å†³ç­–åŠåŸå› ï¼ˆkey_decisionsï¼‰ï¼ŒåŒ…å«timestamp
4. æ€»ç»“å½“å‰çŠ¶æ€ï¼ˆcurrent_statusï¼‰ï¼Œä¸€å¥è¯
5. æå–å¾…åŠäº‹é¡¹ï¼ˆpending_todosï¼‰
6. ä¿ç•™é‡è¦ä¸Šä¸‹æ–‡ï¼ˆimportant_contextï¼‰ï¼š
   - æŠ€æœ¯æ ˆ
   - æ–‡ä»¶è·¯å¾„
   - é…ç½®ä¿¡æ¯
   - å¤–éƒ¨ä¾èµ–

è¿”å›JSONæ ¼å¼ï¼Œä¸¥æ ¼éµå¾ªConversationSummaryç»“æ„ã€‚
"""
        
        response = await self.llm.generate(
            prompt=prompt,
            temperature=0.3,  # ä½æ¸©åº¦ä¿è¯ç¨³å®š
            response_format="json"
        )
        
        return ConversationSummary.model_validate_json(response.content)
    
    async def _merge_summary(
        self, 
        old: ConversationSummary,
        new_messages: List
    ) -> ConversationSummary:
        """å¢é‡åˆå¹¶æ‘˜è¦"""
        prompt = f"""
ç°æœ‰æ‘˜è¦ï¼š
{old.model_dump_json(indent=2)}

æ–°å¢å¯¹è¯ï¼š
{self._format_messages_for_llm(new_messages)}

è¯·æ›´æ–°æ‘˜è¦ï¼š
1. åˆå¹¶æ–°å®Œæˆçš„ä»»åŠ¡åˆ°completed_tasks
2. æ·»åŠ æ–°çš„å…³é”®å†³ç­–åˆ°key_decisions
3. æ›´æ–°current_statusä¸ºæœ€æ–°çŠ¶æ€
4. æ›´æ–°pending_todosï¼ˆç§»é™¤å·²å®Œæˆï¼Œæ·»åŠ æ–°å¢ï¼‰
5. åˆå¹¶important_context

ä¿æŒæ‘˜è¦ç®€æ´ï¼Œç§»é™¤å·²è¿‡æ—¶çš„ä¿¡æ¯ã€‚
"""
        
        response = await self.llm.generate(
            prompt=prompt,
            temperature=0.3,
            response_format="json"
        )
        
        return ConversationSummary.model_validate_json(response.content)
    
    async def _build_context_with_summary(self) -> dict:
        """æ„å»ºå¸¦æ‘˜è¦çš„Context"""
        summary = await self.db.get_latest_summary(self.session_id)
        recent = await self.db.get_messages(
            self.session_id,
            is_summarized=False
        )
        
        return {
            "summary": summary.summary_text if summary else None,
            "messages": recent,
            "workspace": await self.fs.get_file_index(self.session_id)
        }
    
    def _format_summary_text(self, summary: ConversationSummary) -> str:
        """å°†ç»“æ„åŒ–æ‘˜è¦è½¬ä¸ºç»™Agentçœ‹çš„æ–‡æœ¬"""
        return f"""# CONVERSATION SUMMARY

This is a summary of prior messages in this conversation. The user still sees the full conversation.

## Overview
{summary.user_goal}

## Progress
**Current Status**: {summary.current_status}

**Completed Tasks**:
{chr(10).join(f'- {task}' for task in summary.completed_tasks)}

**Key Decisions**:
{chr(10).join(f'- {d["decision"]}: {d["reason"]}' for d in summary.key_decisions)}

**Pending TODOs**:
{chr(10).join(f'- {todo}' for todo in summary.pending_todos)}

**Important Context**:
{chr(10).join(f'- {k}: {v}' for k, v in summary.important_context.items())}
"""
    
    def _format_messages_for_llm(self, messages: List) -> str:
        """æ ¼å¼åŒ–æ¶ˆæ¯ç”¨äºæ‘˜è¦ç”Ÿæˆ"""
        lines = []
        for msg in messages:
            if msg.role == "tool":
                # å·¥å…·ç»“æœåªä¿ç•™æ‘˜è¦
                lines.append(f"[Tool: {msg.tool_name}] {msg.tool_result.get('summary', '')[:200]}")
            else:
                # ç”¨æˆ·/åŠ©æ‰‹æ¶ˆæ¯æˆªæ–­
                content = msg.content[:1000] if len(msg.content) > 1000 else msg.content
                lines.append(f"[{msg.role}] {content}")
        
        return "\n\n".join(lines)
```

### 3.3 ä¸æ–‡ä»¶ç³»ç»Ÿé›†æˆ

```python
# packages/core/context/dual_streams.py

class DualContextStreams:
    """åŒé‡åˆ†èº«ï¼šWorking Memory + File System"""
    
    def __init__(self, conversation_mgr, filesystem):
        self.conversation_mgr = conversation_mgr
        self.fs = filesystem
    
    async def get_full_context(self) -> dict:
        """
        è·å–å®Œæ•´Context
        
        ç»“æ„ï¼š
        - Hot: æ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯ï¼ˆå†…å­˜ï¼‰
        - Cold: æ–‡ä»¶ç³»ç»Ÿç´¢å¼•ï¼ˆç£ç›˜ï¼‰
        """
        # Working Memoryï¼ˆæ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯ï¼‰
        memory_context = await self.conversation_mgr.get_context_for_agent()
        
        # File Systemï¼ˆå…¨é‡æ•°æ®ç´¢å¼•ï¼‰
        file_index = {
            "task": await self.fs.list_dir("task"),
            "research": await self.fs.list_dir("research"),
            "code": await self.fs.list_dir("code"),
            "output": await self.fs.list_dir("output")
        }
        
        return {
            **memory_context,
            "filesystem": {
                "index": file_index,
                "tools": ["read_file", "write_file", "list_files"]
            }
        }
    
    async def store_large_result(
        self, 
        tool_name: str, 
        result: dict
    ) -> dict:
        """
        å­˜å‚¨å¤§å‹å·¥å…·ç»“æœ
        
        ç­–ç•¥ï¼š
        - å°ç»“æœï¼ˆ<5KBï¼‰ï¼šç›´æ¥æ”¾å…¥Message
        - å¤§ç»“æœï¼ˆ>5KBï¼‰ï¼šå­˜æ–‡ä»¶ç³»ç»Ÿï¼ŒMessageä¸­åªæ”¾æ‘˜è¦
        """
        result_size = len(str(result))
        
        if result_size < 5000:
            # å°ç»“æœï¼šç›´æ¥è¿”å›
            return {
                "type": "inline",
                "data": result,
                "summary": f"{tool_name} completed"
            }
        
        # å¤§ç»“æœï¼šå­˜æ–‡ä»¶
        filename = f"temp/{tool_name}_{uuid.uuid4().hex[:8]}.json"
        await self.fs.write(filename, json.dumps(result, indent=2))
        
        # ç”Ÿæˆæ‘˜è¦
        summary = await self._summarize_large_result(tool_name, result)
        
        return {
            "type": "file_reference",
            "file_path": filename,
            "summary": summary,
            "size_bytes": result_size
        }
    
    async def _summarize_large_result(self, tool_name: str, result: dict) -> str:
        """æ‘˜è¦å¤§å‹ç»“æœ"""
        # æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆæ‘˜è¦
        if tool_name == "web_search":
            return f"æœç´¢è¿”å› {len(result.get('results', []))} æ¡ç»“æœï¼Œå·²å­˜å‚¨è‡³æ–‡ä»¶"
        elif tool_name == "read_url":
            return f"ç½‘é¡µå†…å®¹ {len(result.get('content', ''))} å­—ç¬¦ï¼Œå·²å­˜å‚¨è‡³æ–‡ä»¶"
        else:
            return f"{tool_name} ç»“æœå·²å­˜å‚¨è‡³æ–‡ä»¶"
```

## 4. ä¸å…¶ä»–æ¨¡å—çš„é›†æˆ

### 4.1 ä¸Memoryæ¨¡å—é›†æˆ
```python
# Contextç®¡ç†å™¨ä¸ºMemoryæä¾›æ•°æ®æº

class MemoryManager:
    def __init__(self, context_manager: ConversationManager):
        self.context = context_manager
    
    async def extract_facts(self):
        """ä»æ‘˜è¦ä¸­æå–äº‹å®"""
        summary = await self.context.db.get_latest_summary(...)
        facts = self._extract_from_summary(summary.summary)
        return facts
```

### 4.2 ä¸Planningæ¨¡å—é›†æˆ
```python
# Plan Recitationä¾èµ–Contextç®¡ç†

class PlanningManager:
    async def get_current_plan(self):
        """ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–è®¡åˆ’"""
        plan = await self.fs.read("task/plan.md")
        return plan
    
    async def update_context_with_plan(self, context: dict):
        """å°†è®¡åˆ’è¿½åŠ åˆ°Contextæœ«å°¾ï¼ˆPlan Recitationï¼‰"""
        plan = await self.get_current_plan()
        context["system_suffix"] = f"\n\n# CURRENT PLAN\n{plan}"
```

### 4.3 ä¸Context Graphé›†æˆ
```python
# Context Graphè®°å½•æ‘˜è¦æ“ä½œ

class ContextGraphRecorder:
    async def record_summary_creation(self, summary_id: str):
        """è®°å½•æ‘˜è¦åˆ›å»ºäº‹ä»¶"""
        await self.graph.add_node(
            type="context_operation",
            action="create_summary",
            summary_id=summary_id,
            timestamp=now()
        )
```

## 5. KV-Cache ä¼˜åŒ–ç­–ç•¥ ğŸ†• â­

> **æ ¸å¿ƒç›®æ ‡**ï¼šKV-Cache å‘½ä¸­ç‡ > 90%ï¼Œæ€§èƒ½æå‡ 7x

### 5.1 é—®é¢˜ï¼šä¸ºä»€ä¹ˆéœ€è¦ KV-Cache ä¼˜åŒ–ï¼Ÿ

**KV-Cache çš„æœ¬è´¨**ï¼š
Transformer æ¨¡å‹åœ¨ç”Ÿæˆæ—¶ï¼Œå¯¹äºå·²ç»è®¡ç®—è¿‡çš„ Tokenï¼Œå…¶ Key/Value å¯ä»¥è¢«ç¼“å­˜å’Œå¤ç”¨ï¼ŒèŠ‚çœ ~90% çš„è®¡ç®—é‡ã€‚

**ä¼ ç»Ÿ Agent çš„é—®é¢˜**ï¼š
```python
# âŒ é”™è¯¯åšæ³•ï¼šæ¯è½®é‡æ„ context
Round 1: [System] + [User] + "è§„åˆ’ä»»åŠ¡"                      # 3000 tokens è®¡ç®—
Round 2: [System] + [User] + [Plan] + "æ‰§è¡Œæ­¥éª¤1ï¼Œå¯ç”¨å·¥å…·ï¼š{A}" # 3200 tokens é‡æ–°è®¡ç®—
Round 3: [System] + [User] + [Plan] + [Result1] + "æ‰§è¡Œæ­¥éª¤2ï¼Œå¯ç”¨å·¥å…·ï¼š{B}" # 3400 tokens é‡æ–°è®¡ç®—

# é—®é¢˜ï¼š
# 1. æ¯è½®çš„å·¥å…·æè¿°éƒ½å˜åŒ– â†’ å‰ç¼€ä¸ç¨³å®š
# 2. KV-Cache å‘½ä¸­ç‡ ~0% â†’ æ¯è½®éƒ½è¦é‡å¤è®¡ç®—æ‰€æœ‰ Token
# 3. 10 è½®å¯¹è¯æ€»è®¡ç®—é‡ï¼š~35,000 tokens
```

**Manus çš„ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
```python
# âœ… æ­£ç¡®åšæ³•ï¼šAppend-Only + Stable Prefix
Initial:  [System] + [All Tools] + [User]                        # 2000 tokens è®¡ç®—ï¼ˆKV-Cache ç”Ÿæˆï¼‰
Round 1:  ... + <|REASONING|>æˆ‘éœ€è¦...<|TOOL_CALL|>tool_a(...)  # æ–°å¢ 500 tokens
Round 2:  ... + <|TOOL_RESULT|>...<|REASONING|>...<|TOOL_CALL|>... # æ–°å¢ 200 tokensï¼ˆå‰é¢ 2500 tokens ç¼“å­˜å‘½ä¸­ï¼‰
Round 3:  ... + <|TOOL_RESULT|>...<|REASONING|>...<|FINAL_ANSWER|> # æ–°å¢ 300 tokensï¼ˆå‰é¢ 2700 tokens ç¼“å­˜å‘½ä¸­ï¼‰

# æ•ˆæœï¼š
# 1. System Prompt + å·¥å…·å®šä¹‰æ°¸ä¸å˜åŒ– â†’ KV-Cache 100% å‘½ä¸­
# 2. æ¯è½®åªè®¡ç®—æ–°å¢çš„ Token â†’ æ€§èƒ½æå‡ 7x
# 3. 10 è½®å¯¹è¯æ€»è®¡ç®—é‡ï¼š~5,000 tokens
```

---

### 5.2 ä¼˜åŒ–åŸåˆ™

#### åŸåˆ™ 1ï¼šå›ºå®š System Prompt

```python
# âŒ é”™è¯¯ï¼šåŠ¨æ€æ³¨å…¥æ—¶é—´æˆ³
SYSTEM_PROMPT = f"""
ä½ æ˜¯ TokenDance Agentã€‚
å½“å‰æ—¶é—´ï¼š{datetime.now()}  # æ¯æ¬¡éƒ½å˜ï¼
å¯ç”¨æŠ€èƒ½ï¼š{current_skills}      # åŠ¨æ€å˜åŒ–ï¼
"""

# âœ… æ­£ç¡®ï¼šå›ºå®šä¸å˜
SYSTEM_PROMPT = """
<|SYSTEM|>
ä½ æ˜¯ TokenDanceï¼Œä¸€ä¸ªé€šç”¨ AI Agent å¹³å°ã€‚

# æ ¸å¿ƒèƒ½åŠ›
ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å·¥å…·å®Œæˆä»»åŠ¡ï¼š
<|TOOLS|>
{ALL_TOOL_DEFINITIONS}  # æ‰€æœ‰å·¥å…·ä¸€æ¬¡æ€§åŠ è½½ï¼Œæ°¸ä¸å˜åŒ–

# è¡Œä¸ºè§„èŒƒ
1. ä½¿ç”¨ <|REASONING|> æ ‡è®°ä½ çš„æ€è€ƒè¿‡ç¨‹
2. ä½¿ç”¨ <|TOOL_CALL|> è°ƒç”¨å·¥å…·
3. æ¥æ”¶ <|TOOL_RESULT|> åç»§ç»­æ¨ç†
4. å®Œæˆåä½¿ç”¨ <|FINAL_ANSWER|> è¾“å‡ºç»“æœ
"""

# å…³é”®ï¼š
# - System Prompt åœ¨ session å¼€å§‹æ—¶ç”Ÿæˆï¼Œä¹‹åæ°¸ä¸å˜åŒ–
# - æ—¶é—´æˆ³ç­‰åŠ¨æ€ä¿¡æ¯æ”¾åœ¨ User Message æˆ– Tool Output ä¸­
```

---

#### åŸåˆ™ 2ï¼šAppend-Only Context Growth

```python
class AgentSession:
    def __init__(self, user_query: str):
        # åˆå§‹åŒ–å›ºå®š context
        self.context = [
            {"role": "system", "content": FIXED_SYSTEM_PROMPT},  # å›ºå®š
            {"role": "user", "content": user_query}              # å›ºå®š
        ]
        self.kv_cache_valid = True
    
    async def execute_step(self):
        # 1. ç”Ÿæˆæ¨ç†ï¼ˆçº¯è¿½åŠ ï¼‰
        reasoning = await self.llm.generate(
            messages=self.context,
            stop=["<|TOOL_CALL|>", "<|FINAL_ANSWER|>"],
            use_cache=self.kv_cache_valid  # ä½¿ç”¨ KV-Cache
        )
        
        # è¿½åŠ æ¨ç†
        self.context.append({
            "role": "assistant",
            "content": f"<|REASONING|>{reasoning}"
        })
        
        # 2. å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·
        if "<|TOOL_CALL|>" in reasoning:
            tool_call = self.parse_tool_call(reasoning)
            result = await self.execute_tool(tool_call)
            
            # è¿½åŠ å·¥å…·ç»“æœ
            self.context.append({
                "role": "tool",
                "content": f"<|TOOL_RESULT|>{result}"
            })
        
        # å…³é”®ï¼šKV-Cache å§‹ç»ˆæœ‰æ•ˆï¼Œå› ä¸ºæˆ‘ä»¬åªè¿½åŠ 
        self.kv_cache_valid = True

# æ•ˆæœï¼š
# - Round 1: è®¡ç®— 2000 tokens (System + User)
# - Round 2: è®¡ç®— 500 tokens (æ–°å¢éƒ¨åˆ†)ï¼Œå‰ 2000 tokens ç¼“å­˜å‘½ä¸­
# - Round 3: è®¡ç®— 300 tokens (æ–°å¢éƒ¨åˆ†)ï¼Œå‰ 2500 tokens ç¼“å­˜å‘½ä¸­
```

---

#### åŸåˆ™ 3ï¼šç»“æ„åŒ–æ ‡è®° (Structured Tags)

```python
# TokenDance çš„æ ‡è®°ç³»ç»Ÿ

class StructuredTags:
    SYSTEM = "<|SYSTEM|>"              # System Prompt
    TOOLS = "<|TOOLS|>"                # å·¥å…·å®šä¹‰
    USER = "<|USER|>"                  # ç”¨æˆ·è¾“å…¥
    REASONING = "<|REASONING|>"        # Agent æ€è€ƒ
    TOOL_CALL = "<|TOOL_CALL|>"        # å·¥å…·è°ƒç”¨
    TOOL_RESULT = "<|TOOL_RESULT|>"    # å·¥å…·ç»“æœ
    FINAL_ANSWER = "<|FINAL_ANSWER|>"  # æœ€ç»ˆç­”æ¡ˆ

# ç¤ºä¾‹ï¼šä¸€ä¸ªå®Œæ•´çš„å¯¹è¯æµ
"""
<|SYSTEM|>
ä½ æ˜¯ TokenDance Agentã€‚

<|TOOLS|>
1. web_search(query: str) -> List[dict]
2. read_url(url: str) -> str
3. summarize(text: str) -> str

<|USER|>
å¸®æˆ‘ç ”ç©¶ AI å‘å±•è¶‹åŠ¿ã€‚

<|REASONING|>
æˆ‘åº”è¯¥å…ˆæœç´¢ç›¸å…³ä¿¡æ¯...

<|TOOL_CALL|>
web_search(query="AI å‘å±•è¶‹åŠ¿ 2026")

<|TOOL_RESULT|>
[æœç´¢ç»“æœ]

<|REASONING|>
ç°åœ¨å¼€å§‹æ€»ç»“...

<|FINAL_ANSWER|>
æ ¹æ®æˆ‘çš„ç ”ç©¶...
"""

# å¥½å¤„ï¼š
# 1. æ˜ç¡®è¯­ä¹‰è¾¹ç•Œï¼Œæ¨¡å‹ç†è§£æ›´å‡†ç¡®
# 2. ä¾¿äºç³»ç»Ÿè§£æå’Œç¼“å­˜ç®¡ç†
# 3. æ”¯æŒéƒ¨åˆ†æ©ç ï¼ˆä¸‹ä¸€æ¡ï¼‰
```

---

#### åŸåˆ™ 4ï¼šå·¥å…·å®šä¹‰æ©ç  (Tool Definition Masking)

```python
# é—®é¢˜ï¼šæ‰€æœ‰å·¥å…·å®šä¹‰éƒ½åŠ è½½ï¼Œä½†æŸäº›æ­¥éª¤åªéœ€è¦éƒ¨åˆ†å·¥å…·
# è§£å†³ï¼šæ©ç æŠ€æœ¯ï¼ˆAttention Maskï¼‰

class ToolMasking:
    def __init__(self):
        # å·¥å…·å®šä¹‰åœ¨å›ºå®šä½ç½®
        self.tool_positions = {
            "web_search": (100, 150),    # Token 100-150
            "read_url": (151, 200),
            "code_execute": (201, 250),
            "summarize": (251, 300)
        }
    
    def generate_attention_mask(self, available_tools: List[str]) -> List[int]:
        """ç”Ÿæˆ Attention Maskï¼Œè®©æ¨¡å‹"çœ‹ä¸è§"ä¸å¯ç”¨çš„å·¥å…·"""
        total_tokens = 2000
        mask = [1] * total_tokens  # é»˜è®¤å…¨éƒ¨å¯è§
        
        for tool, (start, end) in self.tool_positions.items():
            if tool not in available_tools:
                # æ©ç è¯¥å·¥å…·çš„å®šä¹‰ï¼ˆä½†ä¸åˆ é™¤ï¼‰
                mask[start:end] = [0] * (end - start)
        
        return mask

# æ•ˆæœï¼š
# - å·¥å…·å®šä¹‰æ°¸è¿œåœ¨ context ä¸­ â†’ KV-Cache 100% å‘½ä¸­
# - é€šè¿‡ Attention Mask æ§åˆ¶å¯è§æ€§ â†’ æ¨¡å‹è¡Œä¸ºæ­£ç¡®
# - æ— éœ€é‡æ–°åŠ è½½ context â†’ æ€§èƒ½æœ€ä¼˜
```

---

### 5.3 å®ç°ç¤ºä¾‹

```python
# backend/app/context/kv_cache_optimizer.py

def build_prompt_for_llm(context: dict) -> List[dict]:
    """æ„å»º KV-Cache å‹å¥½çš„ Prompt"""
    messages = []
    
    # 1. å›ºå®š System Promptï¼ˆKV-Cache 100% å‘½ä¸­ï¼‰
    messages.append({
        "role": "system",
        "content": FIXED_SYSTEM_PROMPT  # æ°¸ä¸å˜åŒ–
    })
    
    # 2. æ‘˜è¦ï¼ˆå˜åŒ–é¢‘ç‡ä½ï¼Œå¤§éƒ¨åˆ†æ—¶å€™ KV-Cache å‘½ä¸­ï¼‰
    if context.get("summary"):
        messages.append({
            "role": "system",
            "content": context["summary"]
        })
    
    # 3. æœ€è¿‘æ¶ˆæ¯ï¼ˆAppend-Onlyï¼ŒKV-Cache å¢é‡æ›´æ–°ï¼‰
    messages.extend(context["messages"])
    
    return messages
```

---

### 5.4 æ€§èƒ½å¯¹æ¯”

**ä¼ ç»Ÿæ–¹æ¡ˆ**ï¼ˆæ¯è½®é‡æ„ contextï¼‰ï¼š
```
Round 1: ç”Ÿæˆ Plan          â†’ 3000 tokens è®¡ç®—
Round 2: è°ƒç”¨ web_search    â†’ 3200 tokens é‡æ–°è®¡ç®—
Round 3: è°ƒç”¨ read_url      â†’ 3400 tokens é‡æ–°è®¡ç®—
...
Round 10: ç”ŸæˆæŠ¥å‘Š       â†’ 5000 tokens é‡æ–°è®¡ç®—

æ€»è®¡ç®—é‡ï¼š~35,000 tokens
```

**ä¼˜åŒ–åæ–¹æ¡ˆ**ï¼ˆAppend-Only + Stable Prefixï¼‰ï¼š
```
Initial: å›ºå®š System Prompt â†’ 2000 tokens è®¡ç®—ï¼ˆKV-Cache ç”Ÿæˆï¼‰
Round 1: ç”Ÿæˆ Plan          â†’ æ–°å¢ 500 tokens è®¡ç®—
Round 2: è°ƒç”¨ web_search    â†’ æ–°å¢ 200 tokens è®¡ç®—ï¼ˆå‰é¢ 2500 tokens ç¼“å­˜å‘½ä¸­ï¼‰
Round 3: è°ƒç”¨ read_url      â†’ æ–°å¢ 300 tokens è®¡ç®—ï¼ˆå‰é¢ 2700 tokens ç¼“å­˜å‘½ä¸­ï¼‰
...
Round 10: ç”ŸæˆæŠ¥å‘Š       â†’ æ–°å¢ 800 tokens è®¡ç®—ï¼ˆå‰é¢ 4200 tokens ç¼“å­˜å‘½ä¸­ï¼‰

æ€»è®¡ç®—é‡ï¼š~5,000 tokens
```

**æ€§èƒ½æå‡**ï¼š~7x fasterï¼ˆä»…è®¡ç®—æ–°å¢ Tokenï¼‰

---

## 6. æ€§èƒ½ä¼˜åŒ–ï¼ˆå…¶ä»–ï¼‰

### 5.2 å¼‚æ­¥æ‘˜è¦ç”Ÿæˆ
```python
# æ‘˜è¦ç”Ÿæˆä¸é˜»å¡ç”¨æˆ·æ¶ˆæ¯

@router.post("/messages")
async def send_message(message: str, background_tasks: BackgroundTasks):
    # 1. ç«‹å³è¿”å›å“åº”
    response = await agent.run(message)
    
    # 2. åå°è§¦å‘æ‘˜è¦æ›´æ–°
    background_tasks.add_task(
        conversation_mgr.check_and_update_summary
    )
    
    return response
```

### 5.3 æ‘˜è¦ç¼“å­˜
```python
# æ‘˜è¦æ–‡æœ¬ç¼“å­˜åˆ°Redis

class ConversationManager:
    async def get_summary_text(self, session_id: str) -> Optional[str]:
        # å…ˆæŸ¥ç¼“å­˜
        cached = await self.redis.get(f"summary:{session_id}")
        if cached:
            return cached
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥æ•°æ®åº“
        summary = await self.db.get_latest_summary(session_id)
        if summary:
            await self.redis.setex(
                f"summary:{session_id}",
                3600,  # 1å°æ—¶è¿‡æœŸ
                summary.summary_text
            )
            return summary.summary_text
        
        return None
```

## 6. ç›‘æ§æŒ‡æ ‡

```python
# packages/core/context/metrics.py

class ContextMetrics:
    """Contextç®¡ç†æŒ‡æ ‡"""
    
    async def collect(self, session_id: str) -> dict:
        return {
            # å‹ç¼©æ•ˆæœ
            "total_messages": await self.db.count_messages(session_id),
            "summarized_messages": await self.db.count_summarized(session_id),
            "compression_ratio": await self._calc_compression_ratio(session_id),
            
            # Contextå¤§å°
            "current_context_tokens": await self._calc_current_tokens(session_id),
            "would_be_tokens_without_summary": await self._calc_full_tokens(session_id),
            "tokens_saved": ...,
            
            # æˆæœ¬èŠ‚çœ
            "cost_saved_usd": ...,
            
            # æ‘˜è¦è´¨é‡
            "summary_count": await self.db.count_summaries(session_id),
            "avg_summary_latency_ms": ...
        }
```

## 7. æœªæ¥æ‰©å±•

### 7.1 å¤šæ¨¡æ€æ‘˜è¦
```python
# æ”¯æŒå›¾ç‰‡ã€ä»£ç ç­‰å¤šæ¨¡æ€å†…å®¹çš„æ‘˜è¦

class MultimodalSummarizer:
    async def summarize(self, messages: List):
        text_summary = await self._summarize_text(messages)
        image_summary = await self._summarize_images(messages)
        code_summary = await self._summarize_code(messages)
        
        return {
            "text": text_summary,
            "images": image_summary,
            "code": code_summary
        }
```

### 7.2 è¯­ä¹‰æ£€ç´¢å¢å¼º
```python
# ç»“åˆå‘é‡æ£€ç´¢ï¼Œç²¾å‡†å®šä½å†å²ä¿¡æ¯

class SemanticContextRetrieval:
    async def retrieve_relevant_history(self, query: str, k: int = 5):
        """æ ¹æ®å½“å‰é—®é¢˜æ£€ç´¢ç›¸å…³å†å²"""
        embedding = await self.embed(query)
        
        # ä»å†å²æ¶ˆæ¯ä¸­æ£€ç´¢
        relevant = await self.vector_db.search(
            collection="message_embeddings",
            query_vector=embedding,
            limit=k
        )
        
        return relevant
```

### 7.3 åˆ†æ”¯å¯¹è¯ç®¡ç†
```python
# æ”¯æŒå¯¹è¯åˆ†æ”¯ï¼ˆç”¨æˆ·å›é€€åˆ°å†å²æŸç‚¹ï¼‰

class ConversationBranch:
    async def create_branch(self, from_message_id: str):
        """ä»æŸæ¡æ¶ˆæ¯åˆ›å»ºæ–°åˆ†æ”¯"""
        new_session_id = uuid.uuid4()
        
        # å¤åˆ¶å†å²åˆ°æ–°åˆ†æ”¯
        await self.db.copy_messages_until(
            from_message_id,
            new_session_id
        )
        
        return new_session_id
```

## 8. æ€»ç»“

**æ ¸å¿ƒä»·å€¼**ï¼š
1. **æˆæœ¬é™ä½90%**ï¼š50K tokens â†’ 10K tokens
2. **å»¶è¿Ÿé™ä½80%**ï¼š10ç§’ â†’ 2ç§’
3. **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒæ— é™é•¿å¯¹è¯
4. **ä¿¡æ¯ä¿çœŸ**ï¼šå…³é”®ä¿¡æ¯ä¸ä¸¢å¤±

**å…³é”®æŠ€æœ¯**ï¼š
1. æ»‘åŠ¨çª—å£ + å¢é‡æ‘˜è¦
2. ç»“æ„åŒ–æ‘˜è¦ + è‡ªç„¶è¯­è¨€æ–‡æœ¬
3. åŒé‡åˆ†èº«ï¼šWorking Memory + File System
4. KV Cacheå‹å¥½è®¾è®¡

**ä¸å…¶ä»–æ¨¡å—çš„å…³ç³»**ï¼š
- ä¸ºMemoryæä¾›æ•°æ®æº
- ä¸ºPlanningæä¾›Plan Recitationæ”¯æŒ
- ä¸Context GraphååŒè®°å½•å†³ç­–è½¨è¿¹
- æ‰€æœ‰æ¨¡å—çš„åŸºç¡€è®¾æ–½
