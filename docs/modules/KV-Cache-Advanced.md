# KV-Cache é«˜çº§è®¾è®¡æ–‡æ¡£

> **æ ¸å¿ƒç†å¿µ**ï¼šå°† KV-Cache ä»"åŠ é€Ÿå·¥å…·"å‡çº§ä¸º"Agent é•¿æœŸè®°å¿†"å’Œ"å¤šä»»åŠ¡åˆ‡æ¢å™¨"
> Version: 1.0.0
> Last Updated: 2026-01-09

## 1. è®¾è®¡å“²å­¦

### 1.1 è¶…è¶Šä¼ ç»Ÿï¼šä»å•ä¸€ç¼“å­˜åˆ°åŸºç¡€è®¾æ–½

**ä¼ ç»Ÿ Agent çš„å±€é™**ï¼š
```
ä¸€ä¸ªå¯¹è¯ = ä¸€ä¸ªç‹¬ç«‹çš„ KV-Cache
å¤šä¸ª Agent å®ä¾‹ = é‡å¤çš„å†…å­˜å ç”¨
ä»»åŠ¡åˆ‡æ¢ = é‡æ–°è®¡ç®—å…¨éƒ¨ Context
```

**TokenDance çš„çªç ´**ï¼š
```
KV-Cache ä¸å†æ˜¯"ä¼˜åŒ–æ‰‹æ®µ"ï¼Œè€Œæ˜¯ï¼š
1. Agent çš„é•¿æœŸè®°å¿†å­˜å‚¨
2. å¤šä»»åŠ¡çš„é«˜é€Ÿåˆ‡æ¢å™¨
3. ä¸“å®¶çŸ¥è¯†çš„å³æ—¶åŠ è½½å™¨
```

### 1.2 æ ¸å¿ƒè®¾è®¡åŸåˆ™

| åŸåˆ™ | è¯´æ˜ | ä»·å€¼ |
|------|------|------|
| **å±‚æ¬¡åŒ–å…±äº«** | ä¸‰å±‚ç¼“å­˜æ¶æ„ï¼Œä»å…¨å±€åˆ°ä¼šè¯ | èŠ‚çœ 90% æ˜¾å­˜ |
| **åˆ†æ”¯æ¢ç´¢** | æ”¯æŒå¤šè·¯å¾„å¹¶è¡Œæ¢ç´¢å’Œç§’çº§å›æ»š | å…è®¸è¯•é”™ï¼Œä¸æµªè´¹ç®—åŠ› |
| **æŒä¹…åŒ–è®°å¿†** | ç¼“å­˜å¯ä¿å­˜åˆ°ç£ç›˜ï¼Œæ”¯æŒæ— æ„Ÿå”¤é†’ | Agent æ°¸ä¸å¤±å¿† |
| **é¢„ç½®æ™ºæ…§** | æ€ç»´å¿«ç…§åº“ï¼Œé¢„è£…ä¸“å®¶æ¨ç†é“¾è·¯ | æé€Ÿå“åº”å¤æ‚ä»»åŠ¡ |

---

## 2. å±‚æ¬¡åŒ–ç¼“å­˜æ¶æ„ï¼ˆLayered KV-Cacheï¼‰

### 2.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å±‚æ¬¡åŒ– KV-Cache æ¶æ„                                            â”‚
â”‚                                                                  â”‚
â”‚  Layer 1: Global Static Prefix (å…¨å±€é™æ€å‰ç¼€)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ æ‰€æœ‰å·¥å…·å®šä¹‰ (Browser, Python, Shell, MCP)           â”‚     â”‚
â”‚  â”‚ â€¢ FSM çŠ¶æ€å®šä¹‰                                          â”‚     â”‚
â”‚  â”‚ â€¢ æ ¸å¿ƒè¡Œä¸ºè§„èŒƒ                                          â”‚     â”‚
â”‚  â”‚ â€¢ ç”Ÿå‘½å‘¨æœŸ: ç³»ç»Ÿå†·å¯åŠ¨æ—¶é¢„è®¡ç®—ï¼Œæ°¸ä¸å˜åŒ–               â”‚     â”‚
â”‚  â”‚ â€¢ å…±äº«æœºåˆ¶: Copy-on-Writeï¼Œæ‰€æœ‰ Agent å…±äº«ä¸€ä»½ç‰©ç†å†…å­˜  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                         â†“ æŒ‚è½½                                   â”‚
â”‚  Layer 2: Domain-Specific Modules (ä»»åŠ¡é¢†åŸŸæ¨¡å—)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ Skill-Aware Cache: ä¸ Skill ç³»ç»Ÿæ·±åº¦ç»‘å®š             â”‚     â”‚
â”‚  â”‚ â€¢ æ‡’åŠ è½½: ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶é¢„è®¡ç®—ï¼Œä¹‹åå¤ç”¨                  â”‚     â”‚
â”‚  â”‚ â€¢ ç¤ºä¾‹: "æ•°æ®åˆ†æä¸“å®¶"ã€"ä»£ç é‡æ„ä¸“å®¶"                  â”‚     â”‚
â”‚  â”‚ â€¢ ç”Ÿå‘½å‘¨æœŸ: Skill æ¿€æ´»æ—¶æŒ‚è½½ï¼Œä»»åŠ¡ç»“æŸåå¸è½½            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                         â†“ è¿½åŠ                                    â”‚
â”‚  Layer 3: Session-Specific Delta (ä¼šè¯åŠ¨æ€å±‚)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ ç”¨æˆ·æŒ‡ä»¤ã€Agent æ¨ç†ã€å·¥å…·è¿”å›ç»“æœ                     â”‚     â”‚
â”‚  â”‚ â€¢ Radix Tree ç®¡ç†: è‡ªåŠ¨è¯†åˆ«å…¬å…±å‰ç¼€ï¼Œå¤šä¼šè¯å…±äº«         â”‚     â”‚
â”‚  â”‚ â€¢ Append-Only: åªè¿½åŠ ï¼Œæ°¸ä¸ä¿®æ”¹                         â”‚     â”‚
â”‚  â”‚ â€¢ ç”Ÿå‘½å‘¨æœŸ: ä¼šè¯æœŸé—´æŒç»­å¢é•¿ï¼Œä¼‘çœ åå¯æŒä¹…åŒ–åˆ°ç£ç›˜      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Layer 1: å…¨å±€é™æ€å‰ç¼€ï¼ˆGlobal Static Prefixï¼‰

### 3.1 è®¾è®¡ç›®æ ‡

**æ ¸å¿ƒä»·å€¼**ï¼š
- æ— è®ºè¿è¡Œ 100 ä¸ªè¿˜æ˜¯ 1000 ä¸ª Agent å®ä¾‹ï¼Œç‰©ç†å†…å­˜ä¸­åªå­˜åœ¨ä¸€ä»½é™æ€å‰ç¼€
- é¦–å­—å»¶è¿Ÿå‡ ä¹ä¸º 0ï¼ˆé¢„è®¡ç®—å®Œæˆï¼‰
- èŠ‚çœ 80-90% çš„æ˜¾å­˜å ç”¨

### 3.2 å®ç°æ–¹æ¡ˆ

```python
# backend/app/kv_cache/static_prefix.py

from typing import Optional
import asyncio
from pathlib import Path

class GlobalStaticPrefix:
    """å…¨å±€é™æ€å‰ç¼€ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    
    _instance = None
    _kv_cache_snapshot = None
    _is_initialized = False
    _init_lock = asyncio.Lock()
    
    @classmethod
    def get_instance(cls):
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    async def initialize(self, llm_client):
        """
        ç³»ç»Ÿå†·å¯åŠ¨æ—¶é¢„è®¡ç®—é™æ€å‰ç¼€
        
        è°ƒç”¨æ—¶æœºï¼š
        - æœåŠ¡å™¨å¯åŠ¨æ—¶
        - æ–°å¢å·¥å…·åï¼ˆéœ€è¦é‡æ–°è®¡ç®—ï¼‰
        """
        if self._is_initialized:
            return
        
        async with self._init_lock:
            # Double-check locking
            if self._is_initialized:
                return
            
            # 1. æ„å»ºé™æ€å‰ç¼€ Prompt
            static_prompt = self._build_static_prompt()
            
            print(f"ğŸ“Š Initializing Global Static Prefix ({len(static_prompt)} chars)...")
            
            # 2. é¢„è®¡ç®— KV-Cacheï¼ˆåªç”Ÿæˆ Cacheï¼Œä¸ç”Ÿæˆè¾“å‡ºï¼‰
            self._kv_cache_snapshot = await llm_client.prefill_only(
                messages=[{"role": "system", "content": static_prompt}],
                return_cache=True  # åªè¿”å› KV-Cache
            )
            
            self._is_initialized = True
            
            # 3. ç»Ÿè®¡ä¿¡æ¯
            cache_size_mb = self._kv_cache_snapshot.memory_size / 1024 / 1024
            print(f"âœ… Global Static Prefix initialized: {cache_size_mb:.2f} MB")
    
    def _build_static_prompt(self) -> str:
        """
        æ„å»ºé™æ€å‰ç¼€ï¼ˆæ‰€æœ‰å·¥å…·å®šä¹‰ + æ ¸å¿ƒè§„åˆ™ï¼‰
        
        åŒ…å«ï¼š
        - æ‰€æœ‰å·¥å…·çš„å®Œæ•´å®šä¹‰ï¼ˆBrowser, Python, Shell, MCPï¼‰
        - FSM çŠ¶æ€æœºå®šä¹‰
        - æ ¸å¿ƒè¡Œä¸ºè§„èŒƒ
        - ç»“æ„åŒ–æ ‡è®°ç³»ç»Ÿ
        """
        return f"""<|SYSTEM|>
ä½ æ˜¯ TokenDanceï¼Œä¸€ä¸ªé€šç”¨ AI Agent å¹³å°ã€‚

<|TOOLS|>
{self._load_all_tool_definitions()}

<|FSM_STATES|>
{self._load_fsm_definitions()}

<|CORE_RULES|>
{self._load_core_rules()}

<|STRUCTURED_TAGS|>
- <|REASONING|>: Agent æ¨ç†è¿‡ç¨‹
- <|TOOL_CALL|>: å·¥å…·è°ƒç”¨
- <|TOOL_RESULT|>: å·¥å…·è¿”å›ç»“æœ
- <|FINAL_ANSWER|>: æœ€ç»ˆç­”æ¡ˆ
"""
    
    def _load_all_tool_definitions(self) -> str:
        """åŠ è½½æ‰€æœ‰å·¥å…·å®šä¹‰"""
        from backend.app.tools.registry import tool_registry
        return tool_registry.get_all_tool_definitions()
    
    def _load_fsm_definitions(self) -> str:
        """åŠ è½½ FSM çŠ¶æ€å®šä¹‰"""
        return """
çŠ¶æ€æœºå®šä¹‰ï¼š
- INIT: åˆå§‹åŒ–
- PLANNING: è§„åˆ’
- EXECUTING: æ‰§è¡Œä¸­
- WAITING: ç­‰å¾…å·¥å…·è¿”å›
- REFLECTING: åæ€
- COMPLETED: å®Œæˆ
"""
    
    def _load_core_rules(self) -> str:
        """åŠ è½½æ ¸å¿ƒè¡Œä¸ºè§„èŒƒ"""
        return """
1. æ¯æ¬¡æ¨ç†å‰å¿…é¡»å…ˆæ€è€ƒï¼ˆ<|REASONING|>ï¼‰
2. è°ƒç”¨å·¥å…·å‰å¿…é¡»è¯´æ˜åŸå› 
3. æ”¶åˆ°é”™è¯¯åå¿…é¡»è¿›è¡Œåæ€
4. é«˜é£é™©æ“ä½œå¿…é¡» HITL ç¡®è®¤
"""
    
    def get_cache_snapshot(self) -> 'KVCache':
        """
        è¿”å›åªè¯»çš„ Cache å¿«ç…§ï¼ˆCopy-on-Writeï¼‰
        
        æ¯ä¸ª Agent å®ä¾‹è°ƒç”¨æ­¤æ–¹æ³•æ—¶ï¼Œè¿”å›ä¸€ä¸ªè½»é‡çº§çš„ fork å‰¯æœ¬ã€‚
        ç‰©ç†å†…å­˜ä¸­åªæœ‰ä¸€ä»½ï¼Œé€šè¿‡ Copy-on-Write æœºåˆ¶å…±äº«ã€‚
        """
        if not self._is_initialized:
            raise RuntimeError("Global Static Prefix not initialized. Call initialize() first.")
        
        return self._kv_cache_snapshot.fork()
    
    def invalidate(self):
        """ä½¿ç¼“å­˜å¤±æ•ˆï¼ˆå·¥å…·å®šä¹‰å˜æ›´æ—¶è°ƒç”¨ï¼‰"""
        self._is_initialized = False
        self._kv_cache_snapshot = None
        print("âš ï¸  Global Static Prefix invalidated. Need re-initialization.")


# ä½¿ç”¨ç¤ºä¾‹ï¼šåœ¨æœåŠ¡å™¨å¯åŠ¨æ—¶åˆå§‹åŒ–
async def startup_event():
    """FastAPI å¯åŠ¨äº‹ä»¶"""
    from backend.app.llm.client import llm_client
    
    global_prefix = GlobalStaticPrefix.get_instance()
    await global_prefix.initialize(llm_client)
```

### 3.3 Copy-on-Write æœºåˆ¶

```python
# backend/app/kv_cache/cow.py

class KVCache:
    """KV-Cache æ•°æ®ç»“æ„ï¼ˆæ”¯æŒ Copy-on-Writeï¼‰"""
    
    def __init__(self, keys, values, metadata=None):
        self.keys = keys      # Tensor: (batch, num_heads, seq_len, head_dim)
        self.values = values  # Tensor: (batch, num_heads, seq_len, head_dim)
        self.metadata = metadata or {}
        self._is_fork = False
        self._parent = None
    
    def fork(self) -> 'KVCache':
        """
        åˆ›å»º Fork å‰¯æœ¬ï¼ˆCopy-on-Writeï¼‰
        
        åŸç†ï¼š
        - ä¸å¤åˆ¶ Tensor æ•°æ®ï¼Œåªå¤åˆ¶å¼•ç”¨
        - æ ‡è®°ä¸º fork çŠ¶æ€
        - ç¬¬ä¸€æ¬¡ä¿®æ”¹æ—¶æ‰è§¦å‘çœŸæ­£çš„å¤åˆ¶ï¼ˆç”± PyTorch è‡ªåŠ¨å¤„ç†ï¼‰
        """
        forked = KVCache(
            keys=self.keys,      # å…±äº«å¼•ç”¨
            values=self.values,  # å…±äº«å¼•ç”¨
            metadata=self.metadata.copy()
        )
        forked._is_fork = True
        forked._parent = self
        return forked
    
    @property
    def memory_size(self) -> int:
        """è®¡ç®—å†…å­˜å ç”¨ï¼ˆå­—èŠ‚ï¼‰"""
        keys_size = self.keys.element_size() * self.keys.nelement()
        values_size = self.values.element_size() * self.values.nelement()
        return keys_size + values_size
    
    def to_dict(self) -> dict:
        """åºåˆ—åŒ–ä¸ºå­—å…¸ï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰"""
        return {
            "keys": self.keys.cpu().numpy(),
            "values": self.values.cpu().numpy(),
            "metadata": self.metadata
        }
    
    @classmethod
    def from_dict(cls, data: dict, device: str = "cuda") -> 'KVCache':
        """ä»å­—å…¸ååºåˆ—åŒ–"""
        import torch
        return cls(
            keys=torch.from_numpy(data["keys"]).to(device),
            values=torch.from_numpy(data["values"]).to(device),
            metadata=data["metadata"]
        )
```

---

## 4. Layer 2: ä»»åŠ¡é¢†åŸŸæ¨¡å—ï¼ˆSkill-Aware Cacheï¼‰

### 4.1 è®¾è®¡ç›®æ ‡

**æ ¸å¿ƒä»·å€¼**ï¼š
- ä¸ Skill ç³»ç»Ÿæ·±åº¦ç»‘å®šï¼Œè‡ªåŠ¨è¯†åˆ«ä»»åŠ¡ç±»å‹å¹¶æŒ‚è½½ç›¸åº”çš„ä¸“å®¶çŸ¥è¯†
- æ‡’åŠ è½½ï¼šç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶é¢„è®¡ç®—ï¼Œä¹‹åæ‰€æœ‰å®ä¾‹å¤ç”¨
- å±‚æ¬¡åŒ–æ„å»ºï¼šGlobal Cache â†’ Skill Cache â†’ Session Cache

### 4.2 å®ç°æ–¹æ¡ˆ

```python
# backend/app/kv_cache/skill_cache.py

from typing import Dict, Optional
import asyncio

class SkillCacheManager:
    """æŠ€èƒ½ç›¸å…³çš„ KV-Cache ç®¡ç†å™¨"""
    
    def __init__(self):
        self.skill_caches: Dict[str, KVCache] = {}  # skill_name -> KVCache
        self._cache_lock = asyncio.Lock()
        self._skill_embeddings: Dict[str, list] = {}  # ç”¨äºå¿«é€ŸåŒ¹é…
    
    async def get_or_create_skill_cache(
        self,
        skill_name: str,
        llm_client
    ) -> KVCache:
        """
        è·å–æˆ–åˆ›å»º Skill çš„ KV-Cache
        
        æµç¨‹ï¼š
        1. å¦‚æœç¼“å­˜å­˜åœ¨ï¼Œç›´æ¥è¿”å› fork
        2. å¦åˆ™åŠ è½½ Skill L2 æŒ‡ä»¤å¹¶é¢„è®¡ç®—
        3. åŸºäº Global Prefix æ„å»ºï¼Œé¿å…é‡å¤è®¡ç®—
        """
        # å¿«é€Ÿè·¯å¾„ï¼šç¼“å­˜å‘½ä¸­
        if skill_name in self.skill_caches:
            return self.skill_caches[skill_name].fork()
        
        # æ…¢é€Ÿè·¯å¾„ï¼šåˆ›å»ºæ–°ç¼“å­˜
        async with self._cache_lock:
            # Double-check locking
            if skill_name in self.skill_caches:
                return self.skill_caches[skill_name].fork()
            
            print(f"ğŸ”§ Creating Skill Cache for: {skill_name}")
            
            # 1. åŠ è½½ Skill çš„ L2 æŒ‡ä»¤
            skill_instructions = await self._load_skill_l2(skill_name)
            
            # 2. è·å– Global Cache ä½œä¸ºåŸºç¡€
            global_cache = GlobalStaticPrefix.get_instance().get_cache_snapshot()
            
            # 3. åœ¨ Global Cache åŸºç¡€ä¸Šè¿½åŠ  Skill æŒ‡ä»¤
            skill_cache = await llm_client.prefill_only(
                messages=[{"role": "system", "content": skill_instructions}],
                cache_prefix=global_cache  # å…³é”®ï¼šåŸºäº Global Cache è¿½åŠ 
            )
            
            # 4. ç¼“å­˜èµ·æ¥
            self.skill_caches[skill_name] = skill_cache
            
            # 5. è®¡ç®— embeddingï¼ˆç”¨äºå¿«é€ŸåŒ¹é…ï¼‰
            self._skill_embeddings[skill_name] = await self._compute_embedding(
                skill_instructions
            )
            
            cache_size_mb = skill_cache.memory_size / 1024 / 1024
            print(f"âœ… Skill Cache created: {skill_name} ({cache_size_mb:.2f} MB)")
            
            return skill_cache.fork()
    
    async def _load_skill_l2(self, skill_name: str) -> str:
        """
        åŠ è½½ Skill çš„ L2 æŒ‡ä»¤
        
        ä» skills/{skill_name}/SKILL.md ä¸­æå– L2 éƒ¨åˆ†
        """
        from backend.app.skills.loader import skill_loader
        
        skill_metadata = skill_loader.get_skill(skill_name)
        if not skill_metadata:
            raise ValueError(f"Skill not found: {skill_name}")
        
        # åŠ è½½ L2 æŒ‡ä»¤
        l2_instructions = await skill_loader.load_l2(skill_name)
        
        return f"""<|SKILL:{skill_name}|>
{l2_instructions}
"""
    
    async def _compute_embedding(self, text: str) -> list:
        """è®¡ç®—æ–‡æœ¬ embeddingï¼ˆç”¨äºå¿«é€ŸåŒ¹é…ï¼‰"""
        from backend.app.llm.embedding import embedding_client
        return await embedding_client.embed(text)
    
    async def _store_skill_embedding_to_milvus(self, skill_name: str, embedding: list):
        """å°† Skill embedding å­˜å‚¨åˆ° Milvus"""
        from backend.app.vector_db.milvus_client import milvus_client
        
        await milvus_client.insert(
            collection_name="skill_embeddings",
            data=[{
                "skill_name": skill_name,
                "embedding": embedding,
                "created_at": datetime.now().isoformat()
            }]
        )
    
    async def match_best_skill(self, user_query: str) -> Optional[str]:
        """
        æ ¹æ®ç”¨æˆ·æŸ¥è¯¢åŒ¹é…æœ€é€‚åˆçš„ Skill
        
        ä½¿ç”¨ Milvus å‘é‡ç›¸ä¼¼åº¦æœç´¢
        """
        from backend.app.llm.embedding import embedding_client
        from backend.app.vector_db.milvus_client import milvus_client
        
        # 1. è®¡ç®—æŸ¥è¯¢çš„ embedding
        query_embedding = await embedding_client.embed(user_query)
        
        # 2. åœ¨ Milvus ä¸­æœç´¢æœ€ç›¸ä¼¼çš„ Skill
        results = await milvus_client.search(
            collection_name="skill_embeddings",
            query_vectors=[query_embedding],
            limit=1,
            output_fields=["skill_name"]
        )
        
        if not results or len(results[0]) == 0:
            return None
        
        # 3. è·å–æœ€ä½³åŒ¹é…
        best_match = results[0][0]
        best_skill = best_match.entity.get("skill_name")
        best_score = best_match.distance  # Milvus è¿”å›çš„ç›¸ä¼¼åº¦åˆ†æ•°
        
        # 4. é˜ˆå€¼è¿‡æ»¤
        if best_score > 0.65:  # ç›¸ä¼¼åº¦é˜ˆå€¼
            print(f"ğŸ¯ Matched Skill: {best_skill} (score: {best_score:.2f})")
            return best_skill
        
        return None
    
    def invalidate_skill(self, skill_name: str):
        """ä½¿ Skill Cache å¤±æ•ˆï¼ˆSkill æ›´æ–°æ—¶è°ƒç”¨ï¼‰"""
        if skill_name in self.skill_caches:
            del self.skill_caches[skill_name]
            del self._skill_embeddings[skill_name]
            print(f"âš ï¸  Skill Cache invalidated: {skill_name}")


# ä½¿ç”¨ç¤ºä¾‹ï¼šAgent æ‰§è¡Œæ—¶è‡ªåŠ¨åŒ¹é…å’ŒåŠ è½½
class AgentExecutor:
    async def execute(self, user_query: str):
        """æ‰§è¡Œç”¨æˆ·æŸ¥è¯¢"""
        
        # 1. è‡ªåŠ¨åŒ¹é…æœ€é€‚åˆçš„ Skill
        skill_name = await self.skill_cache_mgr.match_best_skill(user_query)
        
        # 2. åŠ è½½ Skill Cacheï¼ˆåŸºäº Global Cacheï¼‰
        if skill_name:
            self.current_cache = await self.skill_cache_mgr.get_or_create_skill_cache(
                skill_name,
                self.llm_client
            )
        else:
            # ä½¿ç”¨é€šç”¨ Cacheï¼ˆåªæœ‰ Global Prefixï¼‰
            self.current_cache = GlobalStaticPrefix.get_instance().get_cache_snapshot()
        
        # 3. åŸºäº Cache ç”Ÿæˆå“åº”
        response = await self.llm_client.generate(
            messages=[{"role": "user", "content": user_query}],
            cache=self.current_cache
        )
        
        return response
```

### 4.3 ä¸ Skill ç³»ç»Ÿé›†æˆ

```python
# backend/app/skills/loader.py

class SkillLoader:
    async def load_l2_with_cache_hint(self, skill_name: str) -> tuple:
        """
        åŠ è½½ L2 æŒ‡ä»¤ï¼Œå¹¶è¿”å›æ˜¯å¦åº”è¯¥ç¼“å­˜çš„æç¤º
        
        è¿”å›ï¼š(l2_instructions, should_cache)
        """
        l2_instructions = await self.load_l2(skill_name)
        
        # åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜ï¼š
        # - L2 æŒ‡ä»¤è¾ƒé•¿ï¼ˆ> 1000 tokensï¼‰
        # - é«˜é¢‘ä½¿ç”¨çš„ Skillï¼ˆä»ç»Ÿè®¡æ•°æ®åˆ¤æ–­ï¼‰
        should_cache = (
            len(l2_instructions) > 5000 or
            self.get_usage_count(skill_name) > 10
        )
        
        return l2_instructions, should_cache
```

---

## 5. Layer 3: ä¼šè¯åŠ¨æ€å±‚ï¼ˆRadix Treeï¼‰

### 5.1 è®¾è®¡ç›®æ ‡

**æ ¸å¿ƒä»·å€¼**ï¼š
- è‡ªåŠ¨è¯†åˆ«å¤šä¸ªä¼šè¯çš„å…¬å…±å‰ç¼€ï¼Œå…±äº« KV-Cache
- Append-Onlyï¼šåªè¿½åŠ ï¼Œæ°¸ä¸ä¿®æ”¹ï¼Œä¿è¯ KV-Cache æŒç»­æœ‰æ•ˆ
- LRU æ·˜æ±°ï¼šå†…å­˜ä¸è¶³æ—¶è‡ªåŠ¨æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„èŠ‚ç‚¹

### 5.2 Radix Tree æ•°æ®ç»“æ„

```python
# backend/app/kv_cache/radix_tree.py

from typing import Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

@dataclass
class RadixNode:
    """Radix Tree èŠ‚ç‚¹"""
    key: str                    # èŠ‚ç‚¹çš„ Keyï¼ˆæ¶ˆæ¯åºåˆ—çš„ Hashï¼‰
    cache: Optional[KVCache]    # å¯¹åº”çš„ KV-Cache
    children: dict              # å­èŠ‚ç‚¹ï¼šprefix -> RadixNode
    access_time: datetime       # æœ€åè®¿é—®æ—¶é—´ï¼ˆç”¨äº LRUï¼‰
    ref_count: int = 0          # å¼•ç”¨è®¡æ•°


class RadixTree:
    """
    Radix Tree ç”¨äºç®¡ç†ä¼šè¯çº§ KV-Cache
    
    åŸç†ï¼š
    - å¦‚æœä¸¤ä¸ªä¼šè¯å‰ N ä¸ªæ¶ˆæ¯ç›¸åŒï¼Œå®ƒä»¬å…±äº«è¿™éƒ¨åˆ†çš„ Cache
    - ä½¿ç”¨å‰ç¼€æ ‘ç»“æ„è‡ªåŠ¨è¯†åˆ«å…¬å…±å‰ç¼€
    """
    
    def __init__(self, max_nodes: int = 1000):
        self.root = RadixNode(key="", cache=None, children={}, access_time=datetime.now())
        self.max_nodes = max_nodes
        self.node_count = 0
    
    def insert(self, key: str, cache: KVCache):
        """
        æ’å…¥ä¸€ä¸ª Key-Cache å¯¹
        
        å¦‚æœ Key æœ‰å…¬å…±å‰ç¼€ï¼Œè‡ªåŠ¨å…±äº«å‰ç¼€éƒ¨åˆ†çš„ Cache
        """
        node = self.root
        
        for char in key:
            if char not in node.children:
                node.children[char] = RadixNode(
                    key=char,
                    cache=None,
                    children={},
                    access_time=datetime.now()
                )
                self.node_count += 1
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·˜æ±°
                if self.node_count > self.max_nodes:
                    self._evict_lru()
            
            node = node.children[char]
            node.access_time = datetime.now()
        
        # åœ¨å¶å­èŠ‚ç‚¹å­˜å‚¨ Cache
        node.cache = cache
    
    def longest_prefix_match(self, key: str) -> Tuple[Optional[RadixNode], int]:
        """
        æŸ¥æ‰¾æœ€é•¿å…¬å…±å‰ç¼€
        
        è¿”å›ï¼š(åŒ¹é…çš„èŠ‚ç‚¹, åŒ¹é…çš„é•¿åº¦)
        """
        node = self.root
        matched_length = 0
        last_cache_node = None
        
        for i, char in enumerate(key):
            if char not in node.children:
                break
            
            node = node.children[char]
            node.access_time = datetime.now()
            matched_length = i + 1
            
            if node.cache is not None:
                last_cache_node = node
        
        return last_cache_node, matched_length
    
    def _evict_lru(self):
        """æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„èŠ‚ç‚¹ï¼ˆLRUï¼‰"""
        # éå†æ ‘æ‰¾åˆ°æœ€ä¹…æœªä½¿ç”¨çš„å¶å­èŠ‚ç‚¹
        oldest_node = self._find_oldest_leaf(self.root)
        if oldest_node:
            self._remove_node(oldest_node)
            self.node_count -= 1
    
    def _find_oldest_leaf(self, node: RadixNode) -> Optional[RadixNode]:
        """é€’å½’æŸ¥æ‰¾æœ€ä¹…æœªä½¿ç”¨çš„å¶å­èŠ‚ç‚¹"""
        if not node.children:
            return node
        
        oldest = None
        for child in node.children.values():
            candidate = self._find_oldest_leaf(child)
            if candidate and (oldest is None or candidate.access_time < oldest.access_time):
                oldest = candidate
        
        return oldest
    
    def _remove_node(self, node: RadixNode):
        """ç§»é™¤èŠ‚ç‚¹"""
        # é‡Šæ”¾ Cache
        if node.cache:
            del node.cache
        # æ¸…ç©ºå­èŠ‚ç‚¹
        node.children.clear()
```

### 5.3 ä¼šè¯ç¼“å­˜ç®¡ç†å™¨

```python
# backend/app/kv_cache/session_cache.py

import hashlib
import json
from typing import List

class SessionCacheManager:
    """ä¼šè¯çº§ KV-Cache ç®¡ç†å™¨"""
    
    def __init__(self, skill_cache_mgr: SkillCacheManager):
        self.radix_tree = RadixTree(max_nodes=1000)
        self.skill_cache_mgr = skill_cache_mgr
    
    async def get_cache_for_session(
        self,
        session_id: str,
        messages: List[dict],
        skill_name: Optional[str],
        llm_client
    ) -> KVCache:
        """
        è·å–ä¼šè¯çš„ KV-Cache
        
        æµç¨‹ï¼š
        1. è®¡ç®—æ¶ˆæ¯åºåˆ—çš„ Hash Key
        2. åœ¨ Radix Tree ä¸­æŸ¥æ‰¾æœ€é•¿å…¬å…±å‰ç¼€
        3. å¦‚æœå®Œå…¨å‘½ä¸­ï¼Œç›´æ¥è¿”å›
        4. å¦‚æœéƒ¨åˆ†å‘½ä¸­ï¼Œåªè®¡ç®—å·®å¼‚éƒ¨åˆ†
        5. å¦‚æœå®Œå…¨ä¸å‘½ä¸­ï¼ŒåŸºäº Skill Cache è®¡ç®—
        """
        # 1. è®¡ç®—æ¶ˆæ¯åºåˆ—çš„ Key
        message_key = self._compute_message_key(messages)
        
        # 2. æŸ¥æ‰¾æœ€é•¿å…¬å…±å‰ç¼€
        cached_node, cached_length = self.radix_tree.longest_prefix_match(message_key)
        
        # 3. å®Œå…¨å‘½ä¸­
        if cached_node and cached_length == len(message_key):
            print(f"âœ… KV-Cache hit: {cached_length} messages")
            return cached_node.cache.fork()
        
        # 4. éƒ¨åˆ†å‘½ä¸­
        if cached_node and cached_length > 0:
            print(f"ğŸ”¶ KV-Cache partial hit: {cached_length}/{len(messages)} messages")
            
            # åªè®¡ç®—å·®å¼‚éƒ¨åˆ†
            delta_messages = messages[cached_length:]
            new_cache = await llm_client.prefill_only(
                messages=delta_messages,
                cache_prefix=cached_node.cache
            )
        else:
            # 5. å®Œå…¨ä¸å‘½ä¸­
            print(f"âŒ KV-Cache miss, computing from scratch")
            
            # åŸºäº Skill Cache è®¡ç®—
            if skill_name:
                skill_cache = await self.skill_cache_mgr.get_or_create_skill_cache(
                    skill_name,
                    llm_client
                )
            else:
                skill_cache = GlobalStaticPrefix.get_instance().get_cache_snapshot()
            
            new_cache = await llm_client.prefill_only(
                messages=messages,
                cache_prefix=skill_cache
            )
        
        # 6. æ’å…¥ Radix Tree
        self.radix_tree.insert(message_key, new_cache)
        
        return new_cache.fork()
    
    def _compute_message_key(self, messages: List[dict]) -> str:
        """
        è®¡ç®—æ¶ˆæ¯åºåˆ—çš„ Key
        
        ä½¿ç”¨ SHA-256 hash å‰ N ä¸ªæ¶ˆæ¯çš„å†…å®¹
        """
        # åªå–å‰ 100 å­—ç¬¦ï¼Œé¿å… Key è¿‡é•¿
        content = json.dumps([
            {
                "role": m["role"],
                "content": m["content"][:100]
            }
            for m in messages
        ], sort_keys=True)
        
        return hashlib.sha256(content.encode()).hexdigest()
```

---

## 6. KV-Cache åˆ†æ”¯æ¢ç´¢ï¼ˆBranchingï¼‰

### 6.1 è®¾è®¡ç›®æ ‡

**æ ¸å¿ƒä»·å€¼**ï¼š
- å…è®¸ Agent å¹¶è¡Œæ¢ç´¢å¤šä¸ªå†³ç­–è·¯å¾„
- å¤±è´¥åç§’çº§å›æ»šåˆ°åˆ†å‰ç‚¹ï¼Œæ— éœ€é‡æ–°è¾“å…¥ Prompt
- é›¶æˆæœ¬ï¼šåªæ˜¯ç§»åŠ¨å†…å­˜æŒ‡é’ˆ

### 6.2 å®ç°æ–¹æ¡ˆ

```python
# backend/app/kv_cache/branching.py

from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
import uuid

@dataclass
class CacheBranch:
    """KV-Cache åˆ†æ”¯"""
    id: str                         # åˆ†æ”¯ ID
    name: str                       # åˆ†æ”¯åç§°
    parent_cache: KVCache           # åˆ†å‰ç‚¹çš„ Cacheï¼ˆCopy-on-Writeï¼‰
    created_at: datetime
    metadata: dict                  # åˆ†æ”¯å…ƒæ•°æ®ï¼ˆå¦‚ï¼šæ¢ç´¢çš„æ–¹æ¡ˆï¼‰


class CacheBranchManager:
    """KV-Cache åˆ†æ”¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.branches: Dict[str, CacheBranch] = {}
    
    async def create_branch(
        self,
        parent_cache: KVCache,
        branch_name: str,
        metadata: dict = None
    ) -> str:
        """
        åœ¨å½“å‰ Cache çŠ¶æ€åˆ›å»ºåˆ†æ”¯
        
        ç”¨é€”ï¼š
        - Agent é¢ä¸´å¤šä¸ªå†³ç­–è·¯å¾„æ—¶ï¼Œåœ¨åˆ†å‰ç‚¹åˆ›å»ºåˆ†æ”¯
        - å¹¶è¡Œæˆ–ä¸²è¡Œæ¢ç´¢æ¯æ¡è·¯å¾„
        - å¤±è´¥åå¯ä»¥ç§’çº§å›æ»šåˆ°åˆ†å‰ç‚¹
        
        è¿”å›ï¼šbranch_id
        """
        branch_id = f"branch_{uuid.uuid4().hex[:8]}"
        
        # è®°å½•åˆ†å‰ç‚¹ï¼ˆåªä¿å­˜æŒ‡é’ˆï¼Œä¸å¤åˆ¶æ•°æ®ï¼‰
        branch = CacheBranch(
            id=branch_id,
            name=branch_name,
            parent_cache=parent_cache.fork(),  # Copy-on-Write
            created_at=datetime.now(),
            metadata=metadata or {}
        )
        
        self.branches[branch_id] = branch
        
        print(f"ğŸŒ¿ Created branch: {branch_name} (id: {branch_id})")
        
        return branch_id
    
    async def rollback_to_branch(self, branch_id: str) -> KVCache:
        """
        å›æ»šåˆ°åˆ†æ”¯ç‚¹ï¼ˆç§’çº§ï¼‰
        
        åŸç†ï¼š
        - ç›´æ¥è¿”å›åˆ†æ”¯ç‚¹çš„ Cache
        - æ— éœ€é‡æ–°è®¡ç®—ä»»ä½• Token
        """
        branch = self.branches.get(branch_id)
        if not branch:
            raise ValueError(f"Branch not found: {branch_id}")
        
        print(f"â†©ï¸  Rolled back to branch: {branch.name} (id: {branch_id})")
        
        return branch.parent_cache.fork()
    
    def delete_branch(self, branch_id: str):
        """åˆ é™¤åˆ†æ”¯"""
        if branch_id in self.branches:
            del self.branches[branch_id]
            print(f"ğŸ—‘ï¸  Deleted branch: {branch_id}")
    
    def list_branches(self) -> List[CacheBranch]:
        """åˆ—å‡ºæ‰€æœ‰åˆ†æ”¯"""
        return list(self.branches.values())


# ä½¿ç”¨ç¤ºä¾‹ï¼šå¹¶è¡Œæ¢ç´¢å¤šä¸ªæ–¹æ¡ˆ
class AgentExecutor:
    async def explore_multiple_plans(self, plans: List[str]):
        """
        å¹¶è¡Œæ¢ç´¢å¤šä¸ªæ–¹æ¡ˆ
        
        åœºæ™¯ï¼š
        - Agent ç”Ÿæˆäº† 3 ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ
        - éœ€è¦å¹¶è¡Œæµ‹è¯•å“ªä¸ªæ–¹æ¡ˆæœ€ä¼˜
        """
        # 1. åœ¨å½“å‰çŠ¶æ€åˆ›å»ºåˆ†æ”¯
        current_cache = self.current_cache
        
        branches = []
        for plan in plans:
            branch_id = await self.cache_branch_mgr.create_branch(
                parent_cache=current_cache,
                branch_name=f"Plan: {plan[:50]}",
                metadata={"plan": plan}
            )
            branches.append((branch_id, plan))
        
        print(f"ğŸŒ¿ Created {len(branches)} branches for exploration")
        
        # 2. å¹¶è¡Œæ¢ç´¢æ¯ä¸ªåˆ†æ”¯
        results = await asyncio.gather(*[
            self._explore_plan_in_branch(branch_id, plan)
            for branch_id, plan in branches
        ])
        
        # 3. è¯„ä¼°ç»“æœï¼Œé€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
        best_idx = self._select_best_plan(results)
        best_branch_id = branches[best_idx][0]
        
        print(f"ğŸ¯ Selected best plan: Branch {best_idx + 1}")
        
        # 4. å›æ»šåˆ°æœ€ä¼˜åˆ†æ”¯ï¼ˆç§’çº§åˆ‡æ¢ï¼‰
        self.current_cache = await self.cache_branch_mgr.rollback_to_branch(
            best_branch_id
        )
        
        # 5. æ¸…ç†å…¶ä»–åˆ†æ”¯
        for branch_id, _ in branches:
            if branch_id != best_branch_id:
                self.cache_branch_mgr.delete_branch(branch_id)
        
        return results[best_idx]
    
    async def _explore_plan_in_branch(
        self,
        branch_id: str,
        plan: str
    ) -> dict:
        """åœ¨åˆ†æ”¯ä¸­æ¢ç´¢ä¸€ä¸ªæ–¹æ¡ˆ"""
        # è·å–åˆ†æ”¯çš„ Cache
        branch_cache = self.cache_branch_mgr.branches[branch_id].parent_cache.fork()
        
        # åŸºäº Cache ç”Ÿæˆå“åº”
        response = await self.llm_client.generate(
            messages=[{"role": "assistant", "content": f"<|REASONING|>æ‰§è¡Œæ–¹æ¡ˆï¼š{plan}"}],
            cache=branch_cache
        )
        
        # è¯„ä¼°æ–¹æ¡ˆï¼ˆä¾‹å¦‚ï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥ç»“æœï¼‰
        success = await self._evaluate_plan_result(response)
        
        return {
            "plan": plan,
            "response": response,
            "success": success
        }
    
    def _select_best_plan(self, results: List[dict]) -> int:
        """é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ"""
        # ç®€å•ç­–ç•¥ï¼šé€‰æ‹©ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ–¹æ¡ˆ
        for i, result in enumerate(results):
            if result["success"]:
                return i
        
        # å¦‚æœéƒ½å¤±è´¥ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
        return 0
```

---

## 7. KV-Cache æŒä¹…åŒ–ï¼ˆPaging/Swappingï¼‰

### 7.1 è®¾è®¡ç›®æ ‡

**æ ¸å¿ƒä»·å€¼**ï¼š
- Agent ä¼‘çœ æ—¶ï¼Œå°† Cache äº¤æ¢åˆ° Host å†…å­˜ï¼ˆCPU RAMï¼‰æˆ– NVMe ç¡¬ç›˜
- å”¤é†’æ—¶ç¬é—´åŠ è½½ï¼ˆ~100msï¼‰ï¼Œæ— æ„Ÿæ¢å¤çŠ¶æ€
- æ”¯æŒé•¿æœŸè®°å¿†ï¼šå³ä½¿å‡ å¤©æ²¡è¯´è¯ï¼ŒAgent ä¹Ÿä¸ä¼šå¤±å¿†

### 7.2 å®ç°æ–¹æ¡ˆ

```python
# backend/app/kv_cache/persistence.py

import gzip
import pickle
from pathlib import Path
from typing import Optional

class CachePersistenceManager:
    """KV-Cache æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆåŸºäº Redisï¼‰"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379/0"):
        import redis.asyncio as aioredis
        self.redis = aioredis.from_url(redis_url, encoding="utf-8", decode_responses=False)
        self.key_prefix = "kv_cache:"
    
    async def save_cache_to_redis(
        self,
        session_id: str,
        cache: KVCache,
        ttl: Optional[int] = None  # è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone è¡¨ç¤ºæ°¸ä¸è¿‡æœŸ
    ):
        """
        å°† Cache ä¿å­˜åˆ° Redis
        
        åœºæ™¯ï¼š
        - Agent è¿›å…¥ä¼‘çœ çŠ¶æ€
        - ä¼šè¯é•¿æ—¶é—´æœªæ´»è·ƒ
        - æ˜¾å­˜ä¸è¶³ï¼Œéœ€è¦è…¾å‡ºç©ºé—´
        
        ä¼˜åŠ¿ï¼š
        - æ”¯æŒ RDB/AOF æŒä¹…åŒ–
        - è‡ªåŠ¨è¿‡æœŸï¼ˆTTLï¼‰
        - åˆ†å¸ƒå¼è®¿é—®
        """
        key = f"{self.key_prefix}{session_id}"
        
        # 1. åºåˆ—åŒ– Cacheï¼ˆä½¿ç”¨ msgpackï¼Œæ¯” pickle æ›´å¿«æ›´å°ï¼‰
        import msgpack
        serialized = cache.to_dict()
        
        # å°† numpy æ•°ç»„è½¬æ¢ä¸º bytes
        data = {
            "keys": serialized["keys"].tobytes(),
            "values": serialized["values"].tobytes(),
            "keys_shape": serialized["keys"].shape,
            "values_shape": serialized["values"].shape,
            "keys_dtype": str(serialized["keys"].dtype),
            "values_dtype": str(serialized["values"].dtype),
            "metadata": serialized["metadata"]
        }
        
        packed = msgpack.packb(data, use_bin_type=True)
        
        # 2. ä¿å­˜åˆ° Redisï¼ˆè‡ªåŠ¨å‹ç¼©ç”± Redis å¤„ç†ï¼‰
        if ttl:
            await self.redis.setex(key, ttl, packed)
        else:
            await self.redis.set(key, packed)
        
        # 3. ç»Ÿè®¡ä¿¡æ¯
        size_mb = len(packed) / 1024 / 1024
        print(f"ğŸ’¾ Cache saved to Redis: {session_id} ({size_mb:.2f} MB)")
    
    async def load_cache_from_redis(
        self,
        session_id: str,
        device: str = "cuda"
    ) -> Optional[KVCache]:
        """
        ä» Redis åŠ è½½ Cacheï¼ˆæé€Ÿå”¤é†’ï¼‰
        
        åœºæ™¯ï¼š
        - ç”¨æˆ·å”¤é†’ä¼‘çœ çš„ Agent
        - æ¢å¤ä¹‹å‰çš„ä¼šè¯
        
        æ€§èƒ½ï¼š
        - æœ¬åœ° Redis: ~20-50ms
        - è¿œç¨‹ Redis (åŒæœºæˆ¿): ~50-100ms
        """
        key = f"{self.key_prefix}{session_id}"
        
        # 1. ä» Redis è¯»å–
        packed = await self.redis.get(key)
        if not packed:
            return None
        
        print(f"ğŸ“‚ Loading cache from Redis: {session_id}")
        
        # 2. ååºåˆ—åŒ–
        import msgpack
        import numpy as np
        data = msgpack.unpackb(packed, raw=False)
        
        # 3. é‡å»º numpy æ•°ç»„
        keys_array = np.frombuffer(data["keys"], dtype=data["keys_dtype"]).reshape(data["keys_shape"])
        values_array = np.frombuffer(data["values"], dtype=data["values_dtype"]).reshape(data["values_shape"])
        
        serialized = {
            "keys": keys_array,
            "values": values_array,
            "metadata": data["metadata"]
        }
        
        # 4. è½¬æ¢ä¸º KVCache
        cache = KVCache.from_dict(serialized, device=device)
        
        print(f"âœ… Cache loaded from Redis: {session_id}")
        
        return cache
    
    async def delete_cache(self, session_id: str):
        """åˆ é™¤æŒä¹…åŒ–çš„ Cache"""
        key = f"{self.key_prefix}{session_id}"
        deleted = await self.redis.delete(key)
        if deleted:
            print(f"ğŸ—‘ï¸  Cache deleted: {session_id}")
    
    async def list_cached_sessions(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æŒä¹…åŒ–çš„ä¼šè¯"""
        pattern = f"{self.key_prefix}*"
        keys = []
        async for key in self.redis.scan_iter(match=pattern, count=100):
            session_id = key.decode().replace(self.key_prefix, "")
            keys.append(session_id)
        return keys
    
    async def get_cache_ttl(self, session_id: str) -> Optional[int]:
        """è·å– Cache çš„å‰©ä½™ TTLï¼ˆç§’ï¼‰"""
        key = f"{self.key_prefix}{session_id}"
        ttl = await self.redis.ttl(key)
        return ttl if ttl > 0 else None


# ä½¿ç”¨ç¤ºä¾‹ï¼šè‡ªåŠ¨ä¼‘çœ å’Œå”¤é†’
class AgentLifecycleManager:
    async def hibernate_agent(self, session_id: str, ttl: int = 3600 * 24 * 7):
        """Agent è¿›å…¥ä¼‘çœ çŠ¶æ€"""
        # 1. è·å–å½“å‰ Cache
        current_cache = self.get_current_cache(session_id)
        
        # 2. ä¿å­˜åˆ° Redisï¼ˆ7 å¤©åè‡ªåŠ¨è¿‡æœŸï¼‰
        await self.cache_persistence_mgr.save_cache_to_redis(
            session_id,
            current_cache,
            ttl=ttl
        )
        
        # 3. é‡Šæ”¾ GPU å†…å­˜
        del current_cache
        torch.cuda.empty_cache()
        
        print(f"ğŸ˜´ Agent hibernated: {session_id}")
    
    async def wake_up_agent(self, session_id: str) -> bool:
        """å”¤é†’ Agentï¼ˆæé€Ÿæ¢å¤çŠ¶æ€ï¼‰"""
        # 1. ä» Redis åŠ è½½ Cache
        cache = await self.cache_persistence_mgr.load_cache_from_redis(
            session_id,
            device="cuda"
        )
        
        if not cache:
            return False
        
        # 2. æ¢å¤åˆ°å†…å­˜
        self.set_current_cache(session_id, cache)
        
        print(f"ğŸ‘‹ Agent woke up: {session_id}")
        
        return True
```

### 7.3 è‡ªåŠ¨æ¢å…¥æ¢å‡ºç­–ç•¥

```python
# backend/app/kv_cache/auto_paging.py

class AutoPagingManager:
    """è‡ªåŠ¨æ¢å…¥æ¢å‡ºç®¡ç†å™¨"""
    
    def __init__(
        self,
        persistence_mgr: CachePersistenceManager,
        max_gpu_caches: int = 100
    ):
        self.persistence_mgr = persistence_mgr
        self.max_gpu_caches = max_gpu_caches
        self.active_sessions: Dict[str, datetime] = {}  # session_id -> last_access_time
    
    async def on_cache_access(self, session_id: str, cache: KVCache):
        """Cache è¢«è®¿é—®æ—¶è°ƒç”¨"""
        self.active_sessions[session_id] = datetime.now()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·˜æ±°
        if len(self.active_sessions) > self.max_gpu_caches:
            await self._evict_oldest()
    
    async def _evict_oldest(self):
        """æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„ Cache"""
        # æ‰¾åˆ°æœ€ä¹…æœªä½¿ç”¨çš„ session
        oldest_session = min(
            self.active_sessions.items(),
            key=lambda x: x[1]
        )[0]
        
        print(f"ğŸ”„ Evicting cache: {oldest_session}")
        
        # ä¿å­˜åˆ°ç£ç›˜
        cache = self.get_cache(oldest_session)
        await self.persistence_mgr.save_cache_to_disk(oldest_session, cache)
        
        # ä»å†…å­˜ä¸­ç§»é™¤
        self.remove_cache(oldest_session)
        del self.active_sessions[oldest_session]
```

---

## 8. æ€ç»´å¿«ç…§åº“ï¼ˆThought Snapshot Libraryï¼‰

### 8.1 è®¾è®¡å“²å­¦

**æ ¸å¿ƒç†å¿µ**ï¼š
- å°†äººç±»ä¸“å®¶çš„è§£é¢˜è¿‡ç¨‹é¢„å…ˆè·‘ä¸€éï¼ŒæŒä¹…åŒ–ä¸º KV-Cache æ–‡ä»¶
- ç”¨æˆ·å‘èµ·ç±»ä¼¼ä»»åŠ¡æ—¶ï¼Œç›´æ¥åŠ è½½å¿«ç…§ï¼Œç¬é—´æ‹¥æœ‰ä¸“å®¶çº§æ¨ç†é“¾è·¯
- **è·³è¿‡ Prefill é˜¶æ®µ**ï¼Œæé€Ÿå“åº”å¤æ‚ä»»åŠ¡

**ä¸ä¼ ç»Ÿ Few-Shot çš„åŒºåˆ«**ï¼š
| ç»´åº¦ | Few-Shot Prompting | æ€ç»´å¿«ç…§åº“ |
|------|-------------------|-----------|
| **æ–¹å¼** | åœ¨ Prompt ä¸­æä¾›ç¤ºä¾‹ | ç›´æ¥åŠ è½½é¢„è®¡ç®—çš„ KV-Cache |
| **æˆæœ¬** | æ¯æ¬¡éƒ½è¦è®¡ç®—ç¤ºä¾‹çš„ Token | åªè®¡ç®—ä¸€æ¬¡ï¼Œä¹‹åé›¶æˆæœ¬ |
| **æ·±åº¦** | æµ…å±‚ç¤ºä¾‹ï¼ˆ1-2 è½®ï¼‰ | æ·±åº¦æ¨ç†é“¾è·¯ï¼ˆ10+ è½®ï¼‰ |
| **é€Ÿåº¦** | éœ€è¦ Prefill ç¤ºä¾‹ | è·³è¿‡ Prefillï¼Œç§’çº§å“åº” |

### 8.2 å¿«ç…§æ•°æ®ç»“æ„

```python
# backend/app/kv_cache/snapshot.py

from dataclasses import dataclass
from typing import List, Dict

@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    step_num: int
    reasoning: str              # æ€è€ƒè¿‡ç¨‹
    tool_call: Optional[str]    # å·¥å…·è°ƒç”¨
    tool_result: Optional[str]  # å·¥å…·è¿”å›
    timestamp: datetime


@dataclass
class ThoughtSnapshot:
    """æ€ç»´å¿«ç…§"""
    name: str                           # å¿«ç…§åç§°
    description: str                    # æè¿°
    kv_cache: KVCache                   # é¢„è®¡ç®—çš„ KV-Cache
    reasoning_chain: List[ReasoningStep]  # æ¨ç†é“¾è·¯
    tags: List[str]                     # æ ‡ç­¾ï¼ˆç”¨äºæœç´¢ï¼‰
    embedding: Optional[list]           # Embeddingï¼ˆç”¨äºåŒ¹é…ï¼‰
    created_at: datetime
    metadata: Dict                      # å…ƒæ•°æ®
    
    def to_dict(self) -> dict:
        """åºåˆ—åŒ–ä¸ºå­—å…¸ï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰"""
        return {
            "name": self.name,
            "description": self.description,
            "kv_cache": self.kv_cache.to_dict(),
            "reasoning_chain": [
                {
                    "step_num": step.step_num,
                    "reasoning": step.reasoning,
                    "tool_call": step.tool_call,
                    "tool_result": step.tool_result,
                    "timestamp": step.timestamp.isoformat()
                }
                for step in self.reasoning_chain
            ],
            "tags": self.tags,
            "embedding": self.embedding,
            "created_at": self.created_at.isoformat(),
            "metadata": self.metadata
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'ThoughtSnapshot':
        """ä»å­—å…¸ååºåˆ—åŒ–"""
        return cls(
            name=data["name"],
            description=data["description"],
            kv_cache=KVCache.from_dict(data["kv_cache"]),
            reasoning_chain=[
                ReasoningStep(
                    step_num=step["step_num"],
                    reasoning=step["reasoning"],
                    tool_call=step.get("tool_call"),
                    tool_result=step.get("tool_result"),
                    timestamp=datetime.fromisoformat(step["timestamp"])
                )
                for step in data["reasoning_chain"]
            ],
            tags=data["tags"],
            embedding=data.get("embedding"),
            created_at=datetime.fromisoformat(data["created_at"]),
            metadata=data["metadata"]
        )
```

### 8.3 å¿«ç…§åº“ç®¡ç†å™¨

```python
# backend/app/kv_cache/snapshot_library.py

from typing import Optional, List
import numpy as np

class ThoughtSnapshotLibrary:
    """æ€ç»´å¿«ç…§åº“"""
    
    def __init__(self, snapshot_dir: str = "snapshots/"):
        self.snapshot_dir = Path(snapshot_dir)
        self.snapshot_dir.mkdir(parents=True, exist_ok=True)
        self.snapshots: Dict[str, ThoughtSnapshot] = {}
        self._load_all_snapshots()
    
    def _load_all_snapshots(self):
        """åŠ è½½æ‰€æœ‰é¢„ç½®å¿«ç…§"""
        print("ğŸ“š Loading Thought Snapshot Library...")
        
        for snapshot_file in self.snapshot_dir.glob("*.snapshot"):
            name = snapshot_file.stem
            snapshot = self._load_snapshot(snapshot_file)
            self.snapshots[name] = snapshot
            print(f"  âœ… Loaded snapshot: {name}")
        
        print(f"ğŸ“š Loaded {len(self.snapshots)} snapshots")
    
    def _load_snapshot(self, path: Path) -> ThoughtSnapshot:
        """åŠ è½½å•ä¸ªå¿«ç…§æ–‡ä»¶"""
        with gzip.open(path, "rb") as f:
            data = pickle.load(f)
        return ThoughtSnapshot.from_dict(data)
    
    async def match_snapshot(self, user_query: str, threshold: float = 0.7) -> Optional[str]:
        """
        åŒ¹é…æœ€é€‚åˆçš„å¿«ç…§
        
        ä½¿ç”¨ Milvus å‘é‡ç›¸ä¼¼åº¦æœç´¢
        """
        if not self.snapshots:
            return None
        
        from backend.app.llm.embedding import embedding_client
        from backend.app.vector_db.milvus_client import milvus_client
        
        # 1. è®¡ç®—æŸ¥è¯¢çš„ embedding
        query_embedding = await embedding_client.embed(user_query)
        
        # 2. åœ¨ Milvus ä¸­æœç´¢æœ€ç›¸ä¼¼çš„å¿«ç…§
        results = await milvus_client.search(
            collection_name="thought_snapshots",
            query_vectors=[query_embedding],
            limit=1,
            output_fields=["snapshot_name"]
        )
        
        if not results or len(results[0]) == 0:
            return None
        
        # 3. è·å–æœ€ä½³åŒ¹é…
        best_match = results[0][0]
        best_name = best_match.entity.get("snapshot_name")
        best_score = best_match.distance
        
        # 4. é˜ˆå€¼è¿‡æ»¤
        if best_score > threshold:
            print(f"ğŸ¯ Matched Thought Snapshot: {best_name} (score: {best_score:.2f})")
            return best_name
        
        return None
    
    async def _store_snapshot_to_milvus(self, snapshot: ThoughtSnapshot):
        """å°†å¿«ç…§ embedding å­˜å‚¨åˆ° Milvus"""
        from backend.app.vector_db.milvus_client import milvus_client
        
        await milvus_client.insert(
            collection_name="thought_snapshots",
            data=[{
                "snapshot_name": snapshot.name,
                "embedding": snapshot.embedding,
                "description": snapshot.description,
                "tags": snapshot.tags,
                "created_at": snapshot.created_at.isoformat()
            }]
        )
    
    def get_snapshot(self, name: str) -> Optional[ThoughtSnapshot]:
        """è·å–å¿«ç…§"""
        return self.snapshots.get(name)
    
    def list_snapshots(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¿«ç…§"""
        return list(self.snapshots.keys())


# ä½¿ç”¨ç¤ºä¾‹ï¼šåŒ¹é…å¹¶åŠ è½½å¿«ç…§
class AgentExecutor:
    async def execute_with_snapshot(self, user_query: str):
        """ä½¿ç”¨æ€ç»´å¿«ç…§æ‰§è¡Œï¼ˆæé€Ÿå“åº”ï¼‰"""
        
        # 1. å°è¯•åŒ¹é…å¿«ç…§
        snapshot_name = await self.snapshot_lib.match_snapshot(user_query)
        
        if snapshot_name:
            print(f"âš¡ Using Thought Snapshot: {snapshot_name}")
            
            # 2. åŠ è½½å¿«ç…§çš„ KV-Cache
            snapshot = self.snapshot_lib.get_snapshot(snapshot_name)
            self.current_cache = snapshot.kv_cache.fork()
            
            # 3. è·³è¿‡ Prefillï¼Œç›´æ¥ç”Ÿæˆï¼ˆæé€Ÿå“åº”ï¼‰
            response = await self.llm_client.generate(
                messages=[{"role": "user", "content": user_query}],
                cache=self.current_cache,
                skip_prefill=True  # å…³é”®ï¼šè·³è¿‡ Prefill é˜¶æ®µ
            )
            
            print(f"âš¡ Response generated in <1s (using snapshot)")
        else:
            # 4. å¸¸è§„æµç¨‹
            print("ğŸ“ No matching snapshot, using normal flow")
            response = await self.execute_normal(user_query)
        
        return response
```

### 8.4 åˆ›å»ºå¿«ç…§

```python
# tools/create_snapshot.py

async def create_financial_analysis_snapshot():
    """
    åˆ›å»º"è´¢åŠ¡åˆ†æä¸“å®¶"å¿«ç…§
    
    æµç¨‹ï¼š
    1. è®© Agent å®Œæ•´æ‰§è¡Œä¸€ä¸ªè´¢åŠ¡åˆ†æä»»åŠ¡
    2. è®°å½•å®Œæ•´çš„æ¨ç†é“¾è·¯
    3. æ•è· KV-Cache
    4. æŒä¹…åŒ–ä¸ºå¿«ç…§æ–‡ä»¶
    """
    from backend.app.agent.executor import AgentExecutor
    from backend.app.kv_cache.snapshot import ThoughtSnapshot
    
    # 1. å®šä¹‰ä¸“å®¶ä»»åŠ¡
    expert_task = """
åˆ†æä»¥ä¸‹è´¢åŠ¡æŠ¥è¡¨ï¼Œæä¾›æ·±åº¦æ´å¯Ÿï¼š

1. è¥æ”¶åˆ†æï¼šåŒæ¯”/ç¯æ¯”å¢é•¿ç‡ï¼Œä¸»è¦é©±åŠ¨å› ç´ 
2. åˆ©æ¶¦ç‡åˆ†æï¼šæ¯›åˆ©ç‡ã€å‡€åˆ©ç‡ã€è¥ä¸šåˆ©æ¶¦ç‡
3. ç°é‡‘æµåˆ†æï¼šç»è¥ç°é‡‘æµã€è‡ªç”±ç°é‡‘æµ
4. èµ„äº§è´Ÿå€ºç‡ï¼šè´Ÿå€ºç»“æ„ã€å¿å€ºèƒ½åŠ›
5. é£é™©è¯„ä¼°ï¼šè´¢åŠ¡é£é™©ã€ç»è¥é£é™©

è¯·ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
- read_file: è¯»å–è´¢åŠ¡æŠ¥è¡¨æ–‡ä»¶
- python_execute: è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
- web_search: æœç´¢è¡Œä¸šå¯¹æ¯”æ•°æ®
"""
    
    # 2. æ‰§è¡Œä»»åŠ¡å¹¶æ•è·æ¨ç†é“¾è·¯
    agent = AgentExecutor()
    
    cache, reasoning_chain = await agent.execute_and_capture(expert_task)
    
    # 3. è®¡ç®— embedding
    from backend.app.llm.embedding import embedding_client
    embedding = await embedding_client.embed(expert_task)
    
    # 4. åˆ›å»ºå¿«ç…§
    snapshot = ThoughtSnapshot(
        name="financial_analysis_expert",
        description="è´¢åŠ¡åˆ†æä¸“å®¶çš„å®Œæ•´æ¨ç†é“¾è·¯ï¼ŒåŒ…å«è¥æ”¶ã€åˆ©æ¶¦ã€ç°é‡‘æµã€é£é™©è¯„ä¼°ç­‰æ·±åº¦åˆ†æ",
        kv_cache=cache,
        reasoning_chain=reasoning_chain,
        tags=["finance", "analysis", "expert", "deep"],
        embedding=embedding,
        created_at=datetime.now(),
        metadata={
            "task_tokens": len(expert_task.split()),
            "reasoning_steps": len(reasoning_chain),
            "tools_used": ["read_file", "python_execute", "web_search"]
        }
    )
    
    # 5. æŒä¹…åŒ–
    snapshot_path = Path("snapshots/financial_analysis_expert.snapshot")
    with gzip.open(snapshot_path, "wb") as f:
        pickle.dump(snapshot.to_dict(), f)
    
    print(f"âœ… Snapshot created: {snapshot_path}")
    print(f"   - Reasoning steps: {len(reasoning_chain)}")
    print(f"   - Cache size: {cache.memory_size / 1024 / 1024:.2f} MB")


# Agent Executor éœ€è¦æ”¯æŒæ•è·æ¨¡å¼
class AgentExecutor:
    async def execute_and_capture(
        self,
        task: str
    ) -> Tuple[KVCache, List[ReasoningStep]]:
        """
        æ‰§è¡Œä»»åŠ¡å¹¶æ•è· KV-Cache å’Œæ¨ç†é“¾è·¯
        
        ä¸“é—¨ç”¨äºåˆ›å»ºæ€ç»´å¿«ç…§
        """
        reasoning_chain = []
        
        # æ‰§è¡Œä»»åŠ¡
        messages = [{"role": "user", "content": task}]
        
        for step_num in range(1, 100):  # æœ€å¤š 100 æ­¥
            # ç”Ÿæˆæ¨ç†
            response = await self.llm_client.generate(
                messages=messages,
                stop=["<|TOOL_CALL|>", "<|FINAL_ANSWER|>"]
            )
            
            # è®°å½•æ¨ç†æ­¥éª¤
            reasoning_step = ReasoningStep(
                step_num=step_num,
                reasoning=response.content,
                tool_call=None,
                tool_result=None,
                timestamp=datetime.now()
            )
            
            # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨
            if "<|TOOL_CALL|>" in response.content:
                tool_call = self.parse_tool_call(response.content)
                tool_result = await self.execute_tool(tool_call)
                
                reasoning_step.tool_call = tool_call
                reasoning_step.tool_result = tool_result
                
                # è¿½åŠ åˆ° messages
                messages.append({"role": "assistant", "content": response.content})
                messages.append({"role": "tool", "content": f"<|TOOL_RESULT|>{tool_result}"})
            
            # å¦‚æœæ˜¯æœ€ç»ˆç­”æ¡ˆ
            if "<|FINAL_ANSWER|>" in response.content:
                reasoning_chain.append(reasoning_step)
                break
            
            reasoning_chain.append(reasoning_step)
        
        # è·å–å½“å‰ KV-Cache
        final_cache = self.current_cache
        
        return final_cache, reasoning_chain
```

### 8.5 é¢„ç½®å¿«ç…§ç¤ºä¾‹

**å»ºè®®é¢„ç½®çš„å¿«ç…§**ï¼š

1. **`financial_analysis_expert`**: è´¢åŠ¡åˆ†æä¸“å®¶
2. **`code_refactor_expert`**: ä»£ç é‡æ„ä¸“å®¶
3. **`data_analysis_expert`**: æ•°æ®åˆ†æä¸“å®¶ï¼ˆPandas/Matplotlibï¼‰
4. **`deep_research_expert`**: æ·±åº¦ç ”ç©¶ä¸“å®¶ï¼ˆå¤šæºæœç´¢+æ€»ç»“ï¼‰
5. **`ppt_generation_expert`**: PPT ç”Ÿæˆä¸“å®¶
6. **`api_debugging_expert`**: API è°ƒè¯•ä¸“å®¶
7. **`sql_optimization_expert`**: SQL ä¼˜åŒ–ä¸“å®¶
8. **`ui_design_expert`**: UI è®¾è®¡ä¸“å®¶

---

## 9. æŠ€æœ¯æ ˆä¸å®æ–½è·¯çº¿å›¾

### 9.1 æŠ€æœ¯æ ˆé€‰å‹

```python
# å¿…é€‰æŠ€æœ¯æ ˆ
vLLM              # PagedAttention + Prefix Caching
PyTorch           # KV-Cache åºåˆ—åŒ–/ååºåˆ—åŒ–
asyncio           # å¼‚æ­¥ I/O
Redis             # KV-Cache æŒä¹…åŒ–å­˜å‚¨ï¼ˆæ”¯æŒ RDB/AOFï¼‰
Milvus            # å‘é‡æ•°æ®åº“ï¼ˆå¿«ç…§åŒ¹é…ã€Skill åŒ¹é…ï¼‰

# å¯é€‰æŠ€æœ¯æ ˆï¼ˆé«˜çº§ä¼˜åŒ–ï¼‰
Ray               # åˆ†å¸ƒå¼ KV-Cache ç®¡ç†
Redis Cluster     # Redis é›†ç¾¤ï¼ˆå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼ï¼‰
```

### 9.2 å®æ–½è·¯çº¿å›¾

#### Phase 1: åŸºç¡€å±‚ï¼ˆWeek 1-2ï¼‰

**ç›®æ ‡**ï¼šæ­å»ºå±‚æ¬¡åŒ–ç¼“å­˜çš„åŸºç¡€æ¶æ„

- [ ] å®ç° `GlobalStaticPrefix`ï¼ˆå…¨å±€é™æ€å‰ç¼€ï¼‰
- [ ] å®ç° `KVCache` æ•°æ®ç»“æ„ï¼ˆCopy-on-Writeï¼‰
- [ ] é›†æˆ vLLM Prefix Caching
- [ ] å•å…ƒæµ‹è¯•ï¼šéªŒè¯ Copy-on-Write æœºåˆ¶

**éªŒæ”¶æ ‡å‡†**ï¼š
- 100 ä¸ª Agent å®ä¾‹å…±äº«ä¸€ä»½ Global Prefix
- æ˜¾å­˜èŠ‚çœ > 80%

---

#### Phase 2: Skill Cacheï¼ˆWeek 3-4ï¼‰

**ç›®æ ‡**ï¼šå®ç° Skill-Aware Cache

- [ ] å®ç° `SkillCacheManager`
- [ ] ä¸ Skill ç³»ç»Ÿé›†æˆ
- [ ] å®ç°æ‡’åŠ è½½ + é¢„è®¡ç®—
- [ ] å®ç°å‘é‡åŒ¹é…ï¼ˆè‡ªåŠ¨è¯†åˆ« Skillï¼‰

**éªŒæ”¶æ ‡å‡†**ï¼š
- Skill é¦–æ¬¡åŠ è½½ < 2s
- åç»­å¤ç”¨ < 100ms
- è‡ªåŠ¨åŒ¹é…å‡†ç¡®ç‡ > 80%

---

#### Phase 3: Session Cache + Radix Treeï¼ˆWeek 5-6ï¼‰

**ç›®æ ‡**ï¼šå®ç°ä¼šè¯çº§ç¼“å­˜ç®¡ç†

- [ ] å®ç° `RadixTree` æ•°æ®ç»“æ„
- [ ] å®ç° `SessionCacheManager`
- [ ] è‡ªåŠ¨å‰ç¼€æ£€æµ‹
- [ ] LRU æ·˜æ±°ç­–ç•¥

**éªŒæ”¶æ ‡å‡†**ï¼š
- å…¬å…±å‰ç¼€è‡ªåŠ¨è¯†åˆ«
- Cache å‘½ä¸­ç‡ > 70%

---

#### Phase 4: åˆ†æ”¯æ¢ç´¢ï¼ˆWeek 7ï¼‰

**ç›®æ ‡**ï¼šå®ç° KV-Cache Branching

- [ ] å®ç° `CacheBranchManager`
- [ ] æ”¯æŒå¹¶è¡Œæ¢ç´¢å¤šä¸ªæ–¹æ¡ˆ
- [ ] ç§’çº§å›æ»šæœºåˆ¶

**éªŒæ”¶æ ‡å‡†**ï¼š
- åˆ†æ”¯åˆ›å»º < 10ms
- å›æ»šå»¶è¿Ÿ < 100ms

---

#### Phase 5: æŒä¹…åŒ–ï¼ˆWeek 8ï¼‰

**ç›®æ ‡**ï¼šå®ç° KV-Cache Paging

- [ ] å®ç° `CachePersistenceManager`
- [ ] æ”¯æŒä¿å­˜åˆ°ç£ç›˜ï¼ˆå‹ç¼©ï¼‰
- [ ] æ”¯æŒä»ç£ç›˜åŠ è½½ï¼ˆç¬é—´å”¤é†’ï¼‰
- [ ] è‡ªåŠ¨æ¢å…¥æ¢å‡ºç­–ç•¥

**éªŒæ”¶æ ‡å‡†**ï¼š
- ä¿å­˜é€Ÿåº¦ < 500ms
- åŠ è½½é€Ÿåº¦ < 200ms
- å‹ç¼©ç‡ > 50%

---

#### Phase 6: æ€ç»´å¿«ç…§åº“ï¼ˆWeek 9-10ï¼‰

**ç›®æ ‡**ï¼šå®ç° Thought Snapshot Library

- [ ] å®ç° `ThoughtSnapshot` æ•°æ®ç»“æ„
- [ ] å®ç° `ThoughtSnapshotLibrary`
- [ ] åˆ›å»ºå·¥å…·ï¼š`create_snapshot.py`
- [ ] é¢„ç½® 5-8 ä¸ªä¸“å®¶å¿«ç…§

**éªŒæ”¶æ ‡å‡†**ï¼š
- å¿«ç…§åŠ è½½ < 200ms
- åŒ¹é…å‡†ç¡®ç‡ > 75%
- è·³è¿‡ Prefillï¼Œæé€Ÿå“åº”

---

## 10. ç›‘æ§ä¸æŒ‡æ ‡

### 10.1 å…³é”®æŒ‡æ ‡

```python
# backend/app/monitoring/kv_cache_metrics.py

from prometheus_client import Counter, Histogram, Gauge

# KV-Cache å‘½ä¸­ç‡
kv_cache_hit_rate = Gauge(
    "kv_cache_hit_rate",
    "KV-Cache hit rate",
    ["layer"]  # global/skill/session
)

# æ˜¾å­˜èŠ‚çœ
memory_savings = Gauge(
    "kv_cache_memory_savings",
    "Memory savings by KV-Cache sharing (bytes)"
)

# åˆ†æ”¯å›æ»šå»¶è¿Ÿ
branch_rollback_latency = Histogram(
    "kv_cache_branch_rollback_latency_seconds",
    "Branch rollback latency"
)

# å¿«ç…§åŠ è½½å»¶è¿Ÿ
snapshot_load_latency = Histogram(
    "kv_cache_snapshot_load_latency_seconds",
    "Snapshot load latency"
)

# å¿«ç…§åŒ¹é…å‡†ç¡®ç‡
snapshot_match_accuracy = Gauge(
    "kv_cache_snapshot_match_accuracy",
    "Snapshot match accuracy"
)
```

### 10.2 ç›®æ ‡ SLA

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è¯´æ˜ |
|------|--------|------|
| **Global Prefix å‘½ä¸­ç‡** | > 99% | å‡ ä¹æ‰€æœ‰è¯·æ±‚éƒ½å‘½ä¸­ |
| **Skill Cache å‘½ä¸­ç‡** | > 90% | å¤§éƒ¨åˆ†ä»»åŠ¡å¤ç”¨ Skill Cache |
| **Session Cache å‘½ä¸­ç‡** | > 70% | å¤šä¼šè¯å…±äº«å…¬å…±å‰ç¼€ |
| **æ˜¾å­˜èŠ‚çœç‡** | > 80% | ç›¸æ¯”æ— å…±äº«æ–¹æ¡ˆ |
| **åˆ†æ”¯å›æ»šå»¶è¿Ÿ** | < 100ms | ç§’çº§åˆ‡æ¢ |
| **å¿«ç…§åŠ è½½å»¶è¿Ÿ** | < 200ms | ç¬é—´å”¤é†’ |
| **å¿«ç…§åŒ¹é…å‡†ç¡®ç‡** | > 75% | å¤§éƒ¨åˆ†ä»»åŠ¡åŒ¹é…åˆ°å¿«ç…§ |

---

## 11. å¸¸è§é—®é¢˜

### Q1: ä¸ vLLM çš„ Prefix Caching æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**A**: 
- **vLLM Prefix Caching**: è‡ªåŠ¨è¯†åˆ«é‡å¤çš„å‰ç¼€ï¼Œåº•å±‚ä¼˜åŒ–
- **TokenDance å±‚æ¬¡åŒ–ç¼“å­˜**: åœ¨ vLLM åŸºç¡€ä¸Šï¼Œå¢åŠ äº†ä¸‰å±‚æ¶æ„ã€åˆ†æ”¯æ¢ç´¢ã€æ€ç»´å¿«ç…§åº“ç­‰é«˜çº§åŠŸèƒ½
- **å…³ç³»**: TokenDance æ˜¯åº”ç”¨å±‚è®¾è®¡ï¼ŒvLLM æ˜¯åº•å±‚å®ç°

### Q2: Copy-on-Write ä¼šä¸ä¼šå¯¼è‡´å†…å­˜æ³„æ¼ï¼Ÿ

**A**: 
- PyTorch çš„å¼•ç”¨è®¡æ•°æœºåˆ¶ä¼šè‡ªåŠ¨å›æ”¶
- å½“æ‰€æœ‰ fork å‰¯æœ¬éƒ½è¢«é‡Šæ”¾åï¼ŒåŸå§‹ Tensor ä¼šè¢«å›æ”¶
- å»ºè®®å®šæœŸè¿è¡Œ `torch.cuda.empty_cache()` æ¸…ç†ç¢ç‰‡

### Q3: Radix Tree çš„å†…å­˜å¼€é”€æœ‰å¤šå¤§ï¼Ÿ

**A**: 
- æ¯ä¸ªèŠ‚ç‚¹åªå­˜å‚¨æŒ‡é’ˆï¼ˆ~100 bytesï¼‰
- 1000 ä¸ªèŠ‚ç‚¹ â‰ˆ 100KB
- ç›¸æ¯” KV-Cache æœ¬èº«ï¼ˆ~100MBï¼‰ï¼Œå¯å¿½ç•¥ä¸è®¡

### Q4: æ€ç»´å¿«ç…§åº“ä¼šå ç”¨å¤šå°‘ç£ç›˜ç©ºé—´ï¼Ÿ

**A**: 
- å•ä¸ªå¿«ç…§ï¼š50-200MBï¼ˆå‹ç¼©åï¼‰
- 10 ä¸ªå¿«ç…§ï¼š~1GB
- å»ºè®®ä½¿ç”¨ NVMe SSD å­˜å‚¨

### Q5: å¦‚ä½•ä¿è¯å¤šè¿›ç¨‹/å¤šæœºçš„ Cache ä¸€è‡´æ€§ï¼Ÿ

**A**: 
- **å•æœºå¤šè¿›ç¨‹**: ä½¿ç”¨å…±äº«å†…å­˜ï¼ˆ`torch.multiprocessing`ï¼‰
- **å¤šæœº**: ä½¿ç”¨ Ray çš„åˆ†å¸ƒå¼å¯¹è±¡å­˜å‚¨
- **ä¸€è‡´æ€§**: Global Prefix åªè¯»ï¼Œæ— éœ€åŒæ­¥ï¼›Session Cache å„è‡ªç‹¬ç«‹

---

## 12. æ€»ç»“

### 12.1 æ ¸å¿ƒåˆ›æ–°ç‚¹

âœ… **å±‚æ¬¡åŒ–ç¼“å­˜**ï¼šGlobal â†’ Skill â†’ Sessionï¼ŒèŠ‚çœ 90% æ˜¾å­˜
âœ… **åˆ†æ”¯æ¢ç´¢**ï¼šå…è®¸è¯•é”™ï¼Œç§’çº§å›æ»šï¼Œé›¶æˆæœ¬
âœ… **æŒä¹…åŒ–è®°å¿†**ï¼šAgent æ°¸ä¸å¤±å¿†ï¼Œæ”¯æŒæ— æ„Ÿå”¤é†’
âœ… **æ€ç»´å¿«ç…§åº“**ï¼šé¢„è£…ä¸“å®¶æ¨ç†é“¾è·¯ï¼Œæé€Ÿå“åº”å¤æ‚ä»»åŠ¡

### 12.2 ä¸ Manus çš„å¯¹æ¯”

| ç»´åº¦ | Manus | TokenDance |
|------|-------|-----------|
| **ç¼“å­˜å…±äº«** | æ¯ä¸ª Agent ç‹¬ç«‹ | ä¸‰å±‚å…±äº«ï¼ŒèŠ‚çœ 90% æ˜¾å­˜ |
| **ä»»åŠ¡åˆ‡æ¢** | é‡æ–°åŠ è½½ | åˆ†æ”¯æ¢ç´¢ï¼Œç§’çº§åˆ‡æ¢ |
| **é•¿æœŸè®°å¿†** | ä¾èµ–æ–‡ä»¶ç³»ç»Ÿ | KV-Cache æŒä¹…åŒ– + æ€ç»´å¿«ç…§åº“ |
| **ä¸“å®¶çŸ¥è¯†** | ä¾èµ– Prompt | æ€ç»´å¿«ç…§åº“ï¼Œæé€ŸåŠ è½½ |

### 12.3 ä¸šåŠ¡ä»·å€¼

1. **æˆæœ¬é™ä½**ï¼šæ˜¾å­˜èŠ‚çœ 90%ï¼Œæ”¯æŒæ›´å¤šå¹¶å‘ç”¨æˆ·
2. **æ€§èƒ½æå‡**ï¼šåˆ†æ”¯æ¢ç´¢å…è®¸è¯•é”™ï¼Œå¿«ç…§åº“æé€Ÿå“åº”
3. **ç”¨æˆ·ä½“éªŒ**ï¼šAgent æ°¸ä¸å¤±å¿†ï¼Œå”¤é†’æ— æ„ŸçŸ¥
4. **å¯æ‰©å±•æ€§**ï¼šå±‚æ¬¡åŒ–æ¶æ„ï¼Œæ˜“äºæ‰©å±•æ–°åŠŸèƒ½

---

**ä¸‹ä¸€æ­¥**ï¼šå¼€å§‹ Phase 1 å®æ–½ï¼Œæ­å»º Global Static Prefix åŸºç¡€æ¶æ„ï¼ğŸš€
