"""
ResearchAgent - ç ”ç©¶å‹ Agent

æ”¯æŒä½¿ç”¨å·¥å…·è¿›è¡Œä¿¡æ¯æ”¶é›†å’Œç ”ç©¶
"""
import logging
from collections.abc import AsyncGenerator

from ..base import BaseAgent
from ..types import ActionType, AgentAction, SSEEvent, SSEEventType

logger = logging.getLogger(__name__)


class ResearchAgent(BaseAgent):
    """ç ”ç©¶å‹ Agent

    ç‰¹ç‚¹ï¼š
    - æ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆweb_search, read_urlï¼‰
    - è‡ªåŠ¨è®°å½•å‘ç°åˆ° findings.mdï¼ˆ2-Action Ruleï¼‰
    - ç”Ÿæˆç»“æ„åŒ–ç ”ç©¶æŠ¥å‘Š

    ç”¨é€”ï¼š
    - ä¿¡æ¯ç ”ç©¶å’Œæ”¶é›†
    - äº‹å®æ ¸æŸ¥
    - æ·±åº¦è°ƒç ”ä»»åŠ¡
    """

    async def _think(self) -> AsyncGenerator[SSEEvent, None]:
        """æ€è€ƒè¿‡ç¨‹ - ResearchAgent ç‰ˆæœ¬

        ä½¿ç”¨ LLM åˆ†æå½“å‰æƒ…å†µå¹¶åˆ¶å®šè¡ŒåŠ¨è®¡åˆ’

        Yields:
            SSEEvent: thinking äº‹ä»¶
        """
        logger.debug("ResearchAgent thinking...")

        yield SSEEvent(
            type=SSEEventType.THINKING,
            data={'content': 'ğŸ¤” Analyzing task and planning approach...\\n'}
        )

        # æ„é€ æ€è€ƒæç¤º
        system_prompt = """You are a research assistant AI. Analyze the user's question and:
1. Identify what information is needed
2. Determine which tools to use (web_search, read_url)
3. Plan your research approach

Be concise in your thinking."""

        # ä½¿ç”¨ LLM è¿›è¡Œæ€è€ƒ
        thinking_content = ""
        async for chunk in self.llm.stream(
            messages=self.context.messages,
            system=system_prompt
        ):
            thinking_content += chunk
            yield SSEEvent(
                type=SSEEventType.THINKING,
                data={'content': chunk}
            )

        # ä¿å­˜æ€è€ƒå†…å®¹
        self.context.append_thinking(thinking_content)

        logger.debug("Thinking complete")

    async def _decide(self) -> AgentAction:
        """å†³ç­– - ResearchAgent ç‰ˆæœ¬

        åŸºäºæ€è€ƒç»“æœå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š
        - è°ƒç”¨å·¥å…·æ”¶é›†ä¿¡æ¯
        - ç”Ÿæˆæœ€ç»ˆå›ç­”

        Returns:
            AgentAction: å†³ç­–åŠ¨ä½œ
        """
        logger.debug("ResearchAgent making decision...")

        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        tool_definitions = self.tools.to_llm_format()

        if not tool_definitions:
            # æ²¡æœ‰å·¥å…·ï¼Œç›´æ¥å›ç­”
            logger.warning("No tools available, falling back to direct answer")
            return await self._generate_answer()

        # æ„é€ å†³ç­–æç¤º
        system_prompt = """You are a research assistant. Based on the conversation and your thinking:

1. If you need more information, use the available tools:
   - web_search: Search for current information
   - read_url: Read detailed content from a specific URL

2. If you have enough information, provide a comprehensive answer.

3. IMPORTANT: When recording findings after using tools, be concise but informative.

Respond with either a tool call OR a final answer."""

        # è°ƒç”¨ LLM è¿›è¡Œå†³ç­–ï¼ˆæ”¯æŒ Function Callingï¼‰
        response = await self.llm.complete(
            messages=self.context.messages,
            system=system_prompt,
            tools=tool_definitions
        )

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if response.tool_calls:
            # è¿”å›å·¥å…·è°ƒç”¨åŠ¨ä½œ
            tool_call = response.tool_calls[0]  # æš‚æ—¶åªæ”¯æŒå•ä¸ªå·¥å…·è°ƒç”¨

            return AgentAction(
                type=ActionType.TOOL_CALL,
                tool_name=tool_call["name"],
                tool_args=tool_call["input"],
                tool_call_id=tool_call["id"]
            )

        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆå›ç­”
        answer = response.content.strip()

        return AgentAction(
            type=ActionType.ANSWER,
            answer=answer
        )

    async def _generate_answer(self) -> AgentAction:
        """ç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆæ— å·¥å…·æƒ…å†µä¸‹çš„åå¤‡æ–¹æ¡ˆï¼‰

        Returns:
            AgentAction: å›ç­”åŠ¨ä½œ
        """
        system_prompt = "You are a helpful research assistant. Provide a clear and concise answer based on the conversation."

        response = await self.llm.complete(
            messages=self.context.messages,
            system=system_prompt
        )

        return AgentAction(
            type=ActionType.ANSWER,
            answer=response.content.strip()
        )


# ä¾¿æ·å·¥å‚å‡½æ•°
async def create_research_agent(
    context,
    llm,
    tools,
    memory,
    db,
    max_iterations: int = 20
):
    """åˆ›å»º ResearchAgent å®ä¾‹

    Args:
        context: AgentContext
        llm: BaseLLM
        tools: ToolRegistry
        memory: WorkingMemory
        db: AsyncSession
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆç ”ç©¶ä»»åŠ¡å¯èƒ½éœ€è¦æ›´å¤šè¿­ä»£ï¼‰

    Returns:
        ResearchAgent: Agent å®ä¾‹
    """
    agent = ResearchAgent(
        context=context,
        llm=llm,
        tools=tools,
        memory=memory,
        db=db,
        max_iterations=max_iterations
    )

    logger.info(f"ResearchAgent created: {agent}")
    return agent
