"""
Document Preprocessor - Deep Research æ–‡æ¡£é¢„å¤„ç†å™¨

ä½¿ç”¨ MarkItDown å°†ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£è½¬æ¢ä¸º Markdownï¼Œ
ä¾¿äº Agent åˆ†æå’Œæå–å…³é”®ä¿¡æ¯ã€‚

æ”¯æŒåœºæ™¯ï¼š
- ç ”æŠ¥ PDF â†’ Markdown â†’ æå–å…³é”®æ•°æ®
- è´¢æŠ¥ Excel â†’ Table Markdown â†’ è‡ªåŠ¨ç”Ÿæˆåˆ†æ
- Word æ–‡æ¡£ â†’ Markdown â†’ ä½œä¸ºç ”ç©¶ç´ æ
"""
from __future__ import annotations

import logging
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class ConvertedDocument:
    """è½¬æ¢åçš„æ–‡æ¡£"""
    source_path: str
    source_name: str
    file_type: str
    markdown_content: str
    char_count: int
    line_count: int
    metadata: Dict[str, Any]


class DocumentPreprocessor:
    """
    Deep Research ä¸“ç”¨æ–‡æ¡£é¢„å¤„ç†å™¨
    
    å°†ç”¨æˆ·ä¸Šä¼ çš„å„ç±»æ–‡æ¡£ç»Ÿä¸€è½¬æ¢ä¸º Markdown æ ¼å¼ï¼Œ
    ä¾¿äºåç»­çš„ LLM åˆ†æå’Œä¿¡æ¯æå–ã€‚
    """
    
    SUPPORTED_EXTENSIONS = {
        # Office æ–‡æ¡£
        ".pdf": "PDF Document",
        ".docx": "Word Document",
        ".doc": "Word Document (Legacy)",
        ".xlsx": "Excel Spreadsheet",
        ".xls": "Excel Spreadsheet (Legacy)",
        ".pptx": "PowerPoint Presentation",
        # ç»“æ„åŒ–æ•°æ®
        ".csv": "CSV Data",
        ".json": "JSON Data",
        ".xml": "XML Data",
        # ç½‘é¡µ
        ".html": "HTML Page",
        ".htm": "HTML Page",
        # çº¯æ–‡æœ¬
        ".txt": "Plain Text",
        ".md": "Markdown (No conversion needed)",
    }
    
    def __init__(self, llm_client: Optional[Any] = None):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            llm_client: LLM å®¢æˆ·ç«¯ï¼ˆç”¨äºå›¾ç‰‡æè¿°ï¼‰ï¼Œå¯é€‰
        """
        self.llm_client = llm_client
        self._markitdown = None
    
    def _get_markitdown(self):
        """å»¶è¿Ÿåˆå§‹åŒ– MarkItDown"""
        if self._markitdown is None:
            try:
                from markitdown import MarkItDown
                self._markitdown = MarkItDown(
                    llm_client=self.llm_client,
                    enable_plugins=False
                )
                logger.info("MarkItDown initialized for DocumentPreprocessor")
            except ImportError as e:
                logger.error(f"MarkItDown not installed: {e}")
                raise ImportError(
                    "MarkItDown required for document preprocessing. "
                    "Install with: pip install markitdown"
                ) from e
        return self._markitdown
    
    def is_supported(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ”¯æŒè½¬æ¢"""
        ext = Path(file_path).suffix.lower()
        return ext in self.SUPPORTED_EXTENSIONS
    
    def get_file_type(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶ç±»å‹æè¿°"""
        ext = Path(file_path).suffix.lower()
        return self.SUPPORTED_EXTENSIONS.get(ext, "Unknown")
    
    def convert_document(self, file_path: str) -> ConvertedDocument:
        """
        è½¬æ¢å•ä¸ªæ–‡æ¡£
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            ConvertedDocument: è½¬æ¢ç»“æœ
            
        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            ValueError: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        """
        path = Path(file_path)
        
        if not path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        ext = path.suffix.lower()
        
        # Markdown æ–‡ä»¶æ— éœ€è½¬æ¢
        if ext == ".md":
            content = path.read_text(encoding="utf-8")
            return ConvertedDocument(
                source_path=str(path),
                source_name=path.name,
                file_type="Markdown",
                markdown_content=content,
                char_count=len(content),
                line_count=content.count('\n') + 1,
                metadata={"conversion_needed": False}
            )
        
        if not self.is_supported(file_path):
            raise ValueError(
                f"Unsupported file type: {ext}. "
                f"Supported: {list(self.SUPPORTED_EXTENSIONS.keys())}"
            )
        
        # ä½¿ç”¨ MarkItDown è½¬æ¢
        md = self._get_markitdown()
        
        logger.info(f"Converting document: {path.name}")
        result = md.convert(str(path))
        
        markdown_content = result.text_content
        file_size = path.stat().st_size
        
        return ConvertedDocument(
            source_path=str(path),
            source_name=path.name,
            file_type=self.get_file_type(file_path),
            markdown_content=markdown_content,
            char_count=len(markdown_content),
            line_count=markdown_content.count('\n') + 1,
            metadata={
                "file_size_bytes": file_size,
                "file_extension": ext,
                "conversion_needed": True
            }
        )
    
    def convert_multiple(
        self, 
        file_paths: List[str],
        skip_errors: bool = True
    ) -> Dict[str, ConvertedDocument]:
        """
        æ‰¹é‡è½¬æ¢æ–‡æ¡£
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            skip_errors: æ˜¯å¦è·³è¿‡é”™è¯¯ç»§ç»­å¤„ç†
            
        Returns:
            Dict[str, ConvertedDocument]: æ–‡ä»¶å -> è½¬æ¢ç»“æœ
        """
        results = {}
        
        for file_path in file_paths:
            try:
                doc = self.convert_document(file_path)
                results[doc.source_name] = doc
                logger.info(f"Converted: {doc.source_name} ({doc.char_count} chars)")
            except Exception as e:
                logger.error(f"Failed to convert {file_path}: {e}")
                if not skip_errors:
                    raise
        
        return results
    
    def prepare_for_research(
        self,
        documents: List[ConvertedDocument],
        max_total_chars: int = 50000
    ) -> str:
        """
        å°†è½¬æ¢åçš„æ–‡æ¡£æ•´ç†ä¸ºç ”ç©¶ä¸Šä¸‹æ–‡
        
        Args:
            documents: è½¬æ¢åçš„æ–‡æ¡£åˆ—è¡¨
            max_total_chars: æœ€å¤§æ€»å­—ç¬¦æ•°ï¼ˆé˜²æ­¢ Context çˆ†ç‚¸ï¼‰
            
        Returns:
            str: æ•´ç†åçš„ Markdown ä¸Šä¸‹æ–‡
        """
        sections = []
        total_chars = 0
        
        for doc in documents:
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé™åˆ¶
            if total_chars + doc.char_count > max_total_chars:
                # æˆªæ–­å½“å‰æ–‡æ¡£
                available = max_total_chars - total_chars
                if available > 500:  # è‡³å°‘ä¿ç•™ 500 å­—ç¬¦
                    content = doc.markdown_content[:available] + "\n\n[...å†…å®¹å·²æˆªæ–­...]"
                    sections.append(
                        f"## ğŸ“„ {doc.source_name}\n"
                        f"> ç±»å‹: {doc.file_type} | åŸå§‹å¤§å°: {doc.char_count} å­—ç¬¦ (å·²æˆªæ–­)\n\n"
                        f"{content}"
                    )
                break
            
            sections.append(
                f"## ğŸ“„ {doc.source_name}\n"
                f"> ç±»å‹: {doc.file_type} | å¤§å°: {doc.char_count} å­—ç¬¦\n\n"
                f"{doc.markdown_content}"
            )
            total_chars += doc.char_count
        
        header = (
            "# ç ”ç©¶èµ„æ–™\n\n"
            f"ä»¥ä¸‹æ˜¯ç”¨æˆ·æä¾›çš„ {len(sections)} ä»½å‚è€ƒæ–‡æ¡£ï¼Œ"
            "å·²è‡ªåŠ¨è½¬æ¢ä¸º Markdown æ ¼å¼ä¾¿äºåˆ†æã€‚\n\n"
            "---\n\n"
        )
        
        return header + "\n\n---\n\n".join(sections)
    
    def extract_financial_data(self, doc: ConvertedDocument) -> Dict[str, Any]:
        """
        ä»è´¢æŠ¥æ–‡æ¡£ä¸­æå–å…³é”®è´¢åŠ¡æ•°æ®ï¼ˆé‡‘èåœºæ™¯ä¸“ç”¨ï¼‰
        
        Args:
            doc: è½¬æ¢åçš„æ–‡æ¡£ï¼ˆExcel è´¢æŠ¥ï¼‰
            
        Returns:
            Dict: æå–çš„è´¢åŠ¡æ•°æ®
        """
        content = doc.markdown_content
        
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…é¡¹ç›®å¯ç”¨æ›´å¤æ‚çš„ NERï¼‰
        financial_keywords = {
            "è¥ä¸šæ”¶å…¥": ["è¥ä¸šæ”¶å…¥", "è¥æ”¶", "Revenue", "Total Revenue"],
            "å‡€åˆ©æ¶¦": ["å‡€åˆ©æ¶¦", "Net Profit", "Net Income"],
            "æ¯›åˆ©ç‡": ["æ¯›åˆ©ç‡", "Gross Margin"],
            "èµ„äº§è´Ÿå€ºç‡": ["èµ„äº§è´Ÿå€ºç‡", "Debt Ratio"],
            "å¸‚ç›ˆç‡": ["å¸‚ç›ˆç‡", "P/E", "PE"],
        }
        
        extracted = {}
        for metric, keywords in financial_keywords.items():
            for kw in keywords:
                if kw.lower() in content.lower():
                    extracted[metric] = f"åœ¨æ–‡æ¡£ä¸­å‘ç°ã€Œ{kw}ã€ç›¸å…³æ•°æ®"
                    break
        
        return {
            "source": doc.source_name,
            "file_type": doc.file_type,
            "metrics_found": list(extracted.keys()),
            "details": extracted
        }
